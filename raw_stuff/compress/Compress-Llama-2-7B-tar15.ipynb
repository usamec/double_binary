{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1a8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35287ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:38:17.209421Z",
     "iopub.status.busy": "2023-12-26T11:38:17.208962Z",
     "iopub.status.idle": "2023-12-26T11:38:20.906875Z",
     "shell.execute_reply": "2023-12-26T11:38:20.905911Z"
    },
    "papermill": {
     "duration": 3.727175,
     "end_time": "2023-12-26T11:38:20.909562",
     "exception": false,
     "start_time": "2023-12-26T11:38:17.182387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from quant_gpt import *\n",
    "#from sparsegpt import *\n",
    "from modelutils import *\n",
    "from datautils import *\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from bf16_fused_adam import BF16FusedAdamW\n",
    "import datasets\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf0db9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:38:20.927014Z",
     "iopub.status.busy": "2023-12-26T11:38:20.926394Z",
     "iopub.status.idle": "2023-12-26T11:38:20.933689Z",
     "shell.execute_reply": "2023-12-26T11:38:20.932806Z"
    },
    "papermill": {
     "duration": 0.017022,
     "end_time": "2023-12-26T11:38:20.935379",
     "exception": false,
     "start_time": "2023-12-26T11:38:20.918357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_opt(model):\n",
    "    import torch\n",
    "    def skip(*args, **kwargs):\n",
    "        pass\n",
    "    torch.nn.init.kaiming_uniform_ = skip\n",
    "    torch.nn.init.uniform_ = skip\n",
    "    torch.nn.init.normal_ = skip\n",
    "    from transformers import AutoModelForCausalLM\n",
    "    model = AutoModelForCausalLM.from_pretrained(model, torch_dtype=torch.bfloat16, attn_implementation = \"flash_attention_2\")\n",
    "    print(\"ms\", model.config.max_position_embeddings)\n",
    "    model.seqlen = model.config.max_position_embeddings\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d09b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:38:20.949258Z",
     "iopub.status.busy": "2023-12-26T11:38:20.948788Z",
     "iopub.status.idle": "2023-12-26T11:38:40.523396Z",
     "shell.execute_reply": "2023-12-26T11:38:40.522532Z"
    },
    "papermill": {
     "duration": 19.585753,
     "end_time": "2023-12-26T11:38:40.527104",
     "exception": false,
     "start_time": "2023-12-26T11:38:20.941351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fd82ba4df340dcaa2e53f25b7168b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms 4096\n",
      "6738415616 6476267520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "model = get_opt(model_name)\n",
    "model.eval()\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.model.layers.parameters()))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf2732ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:38:40.545044Z",
     "iopub.status.busy": "2023-12-26T11:38:40.544530Z",
     "iopub.status.idle": "2023-12-26T11:39:00.491876Z",
     "shell.execute_reply": "2023-12-26T11:39:00.491195Z"
    },
    "papermill": {
     "duration": 19.957607,
     "end_time": "2023-12-26T11:39:00.494561",
     "exception": false,
     "start_time": "2023-12-26T11:38:40.536954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 4096])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 256\n",
    "\n",
    "ds = datasets.load_from_disk(\"/home/usamec/magic_train/AQLM/redpajama_tokenized_llama2/\")\n",
    "\n",
    "np.random.seed(47)\n",
    "inds = np.random.randint(0, len(ds), size=n_samples)\n",
    "\n",
    "dataloader = torch.LongTensor(ds[inds][\"input_ids\"])\n",
    "dataloader.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b0c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "model.layers.0.input_layernorm.weight\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "model.layers.1.mlp.gate_proj.weight\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "model.layers.1.input_layernorm.weight\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "model.layers.2.input_layernorm.weight\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "model.layers.3.input_layernorm.weight\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "model.layers.4.input_layernorm.weight\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "model.layers.5.input_layernorm.weight\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "model.layers.6.input_layernorm.weight\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "model.layers.7.input_layernorm.weight\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "model.layers.8.input_layernorm.weight\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "model.layers.9.input_layernorm.weight\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "model.layers.10.input_layernorm.weight\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "model.layers.11.input_layernorm.weight\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "model.layers.12.input_layernorm.weight\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "model.layers.13.input_layernorm.weight\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "model.layers.14.input_layernorm.weight\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "model.layers.15.input_layernorm.weight\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "model.layers.16.input_layernorm.weight\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "model.layers.17.input_layernorm.weight\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "model.layers.19.input_layernorm.weight\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "model.layers.20.input_layernorm.weight\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "model.layers.21.input_layernorm.weight\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "model.layers.22.input_layernorm.weight\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "model.layers.23.input_layernorm.weight\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "model.layers.24.input_layernorm.weight\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "model.layers.25.input_layernorm.weight\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "model.layers.26.input_layernorm.weight\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "model.layers.27.input_layernorm.weight\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "model.layers.28.input_layernorm.weight\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "model.layers.29.input_layernorm.weight\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "model.layers.30.input_layernorm.weight\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "model.layers.31.input_layernorm.weight\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "model.norm.weight\n",
      "lm_head.weight\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.28.self_attn.q_proj\n",
      "model.layers.28.self_attn.k_proj\n",
      "model.layers.28.self_attn.v_proj\n",
      "model.layers.28.self_attn.o_proj\n",
      "model.layers.28.mlp.gate_proj\n",
      "model.layers.28.mlp.up_proj\n",
      "model.layers.28.mlp.down_proj\n",
      "model.layers.29.self_attn.q_proj\n",
      "model.layers.29.self_attn.k_proj\n",
      "model.layers.29.self_attn.v_proj\n",
      "model.layers.29.self_attn.o_proj\n",
      "model.layers.29.mlp.gate_proj\n",
      "model.layers.29.mlp.up_proj\n",
      "model.layers.29.mlp.down_proj\n",
      "model.layers.30.self_attn.q_proj\n",
      "model.layers.30.self_attn.k_proj\n",
      "model.layers.30.self_attn.v_proj\n",
      "model.layers.30.self_attn.o_proj\n",
      "model.layers.30.mlp.gate_proj\n",
      "model.layers.30.mlp.up_proj\n",
      "model.layers.30.mlp.down_proj\n",
      "model.layers.31.self_attn.q_proj\n",
      "model.layers.31.self_attn.k_proj\n",
      "model.layers.31.self_attn.v_proj\n",
      "model.layers.31.self_attn.o_proj\n",
      "model.layers.31.mlp.gate_proj\n",
      "model.layers.31.mlp.up_proj\n",
      "model.layers.31.mlp.down_proj\n",
      "torch.Size([4096])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6693, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "0 tensor(0.6693, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9663, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "1 tensor(1.9663, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5742, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "2 tensor(1.5742, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8808, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "3 tensor(1.8808, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6293, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "4 tensor(1.6293, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0618, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "5 tensor(2.0618, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9927, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "6 tensor(1.9927, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2411, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "7 tensor(1.2411, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.4272, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "8 tensor(2.4272, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6823, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "9 tensor(1.6823, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9482, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "10 tensor(1.9482, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.3145, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "11 tensor(2.3145, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3871, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "12 tensor(1.3871, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9845, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "13 tensor(1.9845, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0730, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "14 tensor(2.0730, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7727, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "15 tensor(1.7727, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8592, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "16 tensor(1.8592, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0348, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "17 tensor(2.0348, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6285, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "18 tensor(1.6285, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0577, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "19 tensor(2.0577, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3327, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "20 tensor(1.3327, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7566, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "21 tensor(1.7566, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2625, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "22 tensor(2.2625, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8754, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "23 tensor(1.8754, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8931, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "24 tensor(1.8931, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.6263, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "25 tensor(0.6263, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2890, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "26 tensor(2.2890, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8947, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "27 tensor(1.8947, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9511, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "28 tensor(1.9511, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1401, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "29 tensor(2.1401, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "30 tensor(1.6094, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2028, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "31 tensor(2.2028, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6731, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "32 tensor(1.6731, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.6101, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "33 tensor(0.6101, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.9737, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "34 tensor(0.9737, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0145, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "35 tensor(2.0145, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8115, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "36 tensor(1.8115, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2998, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "37 tensor(2.2998, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7645, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "38 tensor(1.7645, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8529, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "39 tensor(1.8529, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.8614, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "40 tensor(0.8614, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.1030, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "41 tensor(0.1030, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0317, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "42 tensor(2.0317, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4054, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "43 tensor(1.4054, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.7011, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "44 tensor(0.7011, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.0596, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "45 tensor(1.0596, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0262, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "46 tensor(2.0262, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n",
      "tensor(1.8014, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "47 tensor(1.8014, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5257, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "48 tensor(1.5257, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2213, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "49 tensor(1.2213, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5116, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "50 tensor(1.5116, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5719, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "51 tensor(1.5719, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0232, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "52 tensor(2.0232, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8966, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "53 tensor(1.8966, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8332, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "54 tensor(1.8332, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5027, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "55 tensor(1.5027, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9296, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "56 tensor(1.9296, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4265, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "57 tensor(1.4265, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2696, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "58 tensor(1.2696, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6515, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "59 tensor(1.6515, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1666, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "60 tensor(2.1666, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9771, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "61 tensor(1.9771, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6544, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "62 tensor(1.6544, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8737, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "63 tensor(1.8737, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7910, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "64 tensor(1.7910, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8391, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "65 tensor(1.8391, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9295, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "66 tensor(1.9295, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.1431, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "67 tensor(1.1431, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3241, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "68 tensor(1.3241, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0704, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "69 tensor(2.0704, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6958, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "70 tensor(1.6958, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.4191, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "71 tensor(2.4191, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8710, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "72 tensor(1.8710, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8059, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "73 tensor(1.8059, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4305, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "74 tensor(1.4305, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2617, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "75 tensor(1.2617, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2417, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "76 tensor(1.2417, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9748, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "77 tensor(1.9748, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7347, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "78 tensor(1.7347, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8933, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "79 tensor(1.8933, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8148, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "80 tensor(1.8148, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6301, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "81 tensor(1.6301, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8358, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "82 tensor(1.8358, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7578, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "83 tensor(1.7578, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.8792, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "84 tensor(0.8792, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1694, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "85 tensor(2.1694, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7653, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "86 tensor(1.7653, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4363, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "87 tensor(1.4363, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2896, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "88 tensor(2.2896, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5896, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "89 tensor(1.5896, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3302, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "90 tensor(1.3302, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2563, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "91 tensor(2.2563, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5756, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "92 tensor(1.5756, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1464, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "93 tensor(2.1464, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0380, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "94 tensor(2.0380, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8078, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "95 tensor(1.8078, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5278, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "96 tensor(1.5278, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8290, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "97 tensor(1.8290, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3884, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "98 tensor(1.3884, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9057, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "99 tensor(1.9057, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1646, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "100 tensor(2.1646, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7988, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "101 tensor(1.7988, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5663, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "102 tensor(1.5663, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0584, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "103 tensor(2.0584, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0371, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "104 tensor(2.0371, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.1984, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "105 tensor(1.1984, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0724, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "106 tensor(2.0724, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.8909, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "107 tensor(0.8909, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9112, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "108 tensor(1.9112, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5806, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "109 tensor(1.5806, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2574, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "110 tensor(2.2574, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.9743, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "111 tensor(0.9743, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0800, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "112 tensor(2.0800, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9812, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "113 tensor(1.9812, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1298, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "114 tensor(2.1298, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3394, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "115 tensor(1.3394, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8434, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "116 tensor(1.8434, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.3002, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "117 tensor(2.3002, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8721, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "118 tensor(1.8721, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2338, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "119 tensor(2.2338, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9774, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "120 tensor(1.9774, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3857, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "121 tensor(1.3857, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8993, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "122 tensor(1.8993, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6556, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "123 tensor(1.6556, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7281, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "124 tensor(1.7281, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2051, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "125 tensor(2.2051, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6410, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "126 tensor(1.6410, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8792, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "127 tensor(1.8792, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7871, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "128 tensor(1.7871, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7018, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "129 tensor(1.7018, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8767, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "130 tensor(1.8767, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7224, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "131 tensor(1.7224, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8091, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "132 tensor(1.8091, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9524, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "133 tensor(1.9524, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3637, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "134 tensor(1.3637, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.6293, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "135 tensor(0.6293, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6425, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "136 tensor(1.6425, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0885, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "137 tensor(2.0885, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4287, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "138 tensor(1.4287, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n",
      "tensor(2.1759, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "139 tensor(2.1759, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9938, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "140 tensor(1.9938, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5613, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "141 tensor(1.5613, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8946, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "142 tensor(1.8946, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.0776, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "143 tensor(1.0776, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9010, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "144 tensor(1.9010, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7893, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "145 tensor(1.7893, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8178, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "146 tensor(1.8178, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.0577, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "147 tensor(1.0577, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3431, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "148 tensor(1.3431, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6353, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "149 tensor(1.6353, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3692, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "150 tensor(1.3692, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6873, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "151 tensor(1.6873, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5570, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "152 tensor(1.5570, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7841, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "153 tensor(1.7841, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0338, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "154 tensor(2.0338, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0351, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "155 tensor(2.0351, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8860, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "156 tensor(1.8860, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "157 tensor(1.6152, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9144, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "158 tensor(1.9144, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1954, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "159 tensor(2.1954, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1188, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "160 tensor(2.1188, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9598, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "161 tensor(1.9598, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8342, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "162 tensor(1.8342, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2156, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "163 tensor(2.2156, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8315, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "164 tensor(1.8315, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2496, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "165 tensor(2.2496, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9931, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "166 tensor(1.9931, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2033, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "167 tensor(2.2033, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0211, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "168 tensor(2.0211, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9094, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "169 tensor(1.9094, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4666, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "170 tensor(1.4666, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5188, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "171 tensor(1.5188, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.8531, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "172 tensor(0.8531, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.1106, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "173 tensor(1.1106, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6267, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "174 tensor(1.6267, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2111, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "175 tensor(2.2111, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.6093, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "176 tensor(0.6093, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4049, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "177 tensor(1.4049, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9230, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "178 tensor(1.9230, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1119, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "179 tensor(2.1119, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3202, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "180 tensor(1.3202, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9493, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "181 tensor(1.9493, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6634, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "182 tensor(1.6634, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2474, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "183 tensor(1.2474, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.4028, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "184 tensor(2.4028, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n",
      "tensor(1.5242, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "185 tensor(1.5242, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0018, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "186 tensor(2.0018, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0468, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "187 tensor(2.0468, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.5729, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "188 tensor(2.5729, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.8636, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "189 tensor(0.8636, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2638, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "190 tensor(1.2638, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9163, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "191 tensor(1.9163, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0924, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "192 tensor(2.0924, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1153, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "193 tensor(2.1153, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0714, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "194 tensor(2.0714, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8277, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "195 tensor(1.8277, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5257, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "196 tensor(1.5257, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3426, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "197 tensor(1.3426, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0748, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "198 tensor(2.0748, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2688, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "199 tensor(1.2688, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9187, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "200 tensor(1.9187, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2750, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "201 tensor(2.2750, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0396, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "202 tensor(2.0396, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.4038, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "203 tensor(2.4038, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9818, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "204 tensor(1.9818, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7813, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "205 tensor(1.7813, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.8319, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "206 tensor(0.8319, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0524, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "207 tensor(2.0524, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7347, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "208 tensor(1.7347, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6597, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "209 tensor(1.6597, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2123, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "210 tensor(2.2123, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.3413, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "211 tensor(1.3413, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8512, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "212 tensor(1.8512, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8145, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "213 tensor(1.8145, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9969, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "214 tensor(1.9969, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.2746, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "215 tensor(2.2746, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8934, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "216 tensor(1.8934, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.6341, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "217 tensor(0.6341, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0471, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "218 tensor(2.0471, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5614, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "219 tensor(1.5614, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0224, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "220 tensor(2.0224, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.9463, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "221 tensor(0.9463, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5374, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "222 tensor(1.5374, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.3682, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "223 tensor(0.3682, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0327, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "224 tensor(2.0327, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8602, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "225 tensor(1.8602, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8465, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "226 tensor(1.8465, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1460, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "227 tensor(2.1460, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.8307, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "228 tensor(0.8307, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8786, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "229 tensor(1.8786, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1705, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "230 tensor(2.1705, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n",
      "tensor(2.1884, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "231 tensor(2.1884, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9889, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "232 tensor(1.9889, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4893, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "233 tensor(1.4893, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5654, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "234 tensor(1.5654, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.8601, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "235 tensor(0.8601, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.5498, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "236 tensor(1.5498, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8469, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "237 tensor(1.8469, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8797, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "238 tensor(1.8797, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7147, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "239 tensor(1.7147, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8982, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "240 tensor(1.8982, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.1462, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "241 tensor(2.1462, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.7170, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "242 tensor(1.7170, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.4589, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "243 tensor(2.4589, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8298, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "244 tensor(1.8298, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.1479, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "245 tensor(1.1479, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.1223, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "246 tensor(0.1223, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.4913, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "247 tensor(1.4913, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.6911, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "248 tensor(1.6911, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.2194, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "249 tensor(1.2194, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.8959, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "250 tensor(1.8959, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(0.6636, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "251 tensor(0.6636, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0207, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "252 tensor(2.0207, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.1068, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "253 tensor(1.1068, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(1.9658, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "254 tensor(1.9658, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([4096])\n",
      "tensor(2.0856, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "255 tensor(2.0856, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "from cut_cross_entropy import linear_cross_entropy\n",
    "\n",
    "model.cuda()\n",
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False\n",
    "model.train()\n",
    "\n",
    "def f_hook(m, i, o):\n",
    "    X = i[0].detach().float()\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    m.i_norm += X.square().mean(dim=0)\n",
    "    \n",
    "def b_hook(m, _, go):\n",
    "    X = go[0].detach().float()\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    m.o_norm += X.square().mean(dim=0) * 1e6\n",
    "\n",
    "for n, p in model.named_parameters():\n",
    "    print(n)\n",
    "    if \"embed_tokens\" not in n:\n",
    "        p.requires_grad = False\n",
    "\n",
    "handles = []\n",
    "\n",
    "for n, m in model.named_modules():\n",
    "    if type(m) == nn.Linear and \"lm_head\" not in n:\n",
    "        print(n)\n",
    "        m.i_norm = torch.zeros(m.weight.shape[1], device=m.weight.device)\n",
    "        m.o_norm = torch.zeros(m.weight.shape[0], device=m.weight.device)\n",
    "        handles.append(m.register_forward_hook(f_hook))\n",
    "        handles.append(m.register_full_backward_hook(b_hook))\n",
    "\n",
    "for idx, bx in enumerate(dataloader):\n",
    "    #print(bx)\n",
    "    print(bx.shape)\n",
    "    bx = bx.cuda().unsqueeze(0)\n",
    "    #lm_logits = model(bx.cuda()).logits\n",
    "    embs = model.model(bx.cuda())[0]\n",
    "    #shift_logits = lm_logits[:, :-1, :].contiguous()\n",
    "    #shift_labels = bx[:, 1:]\n",
    "    #loss_fct = nn.CrossEntropyLoss()\n",
    "    #loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    loss = linear_cross_entropy(embs, model.lm_head.weight, bx, shift=1)\n",
    "    print(loss)\n",
    "    #print(loss2)\n",
    "    #qq = qqqq\n",
    "    print(idx, loss)\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    \n",
    "for h in handles:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813e9daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8329,  2.7413, -5.5443])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 5)\n",
    "a.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8596d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration(A, num_iters=5):\n",
    "    \"\"\"\n",
    "    Performs power iteration to compute the top singular vectors and value.\n",
    "    \n",
    "    Arguments:\n",
    "        A (torch.Tensor): The input matrix of shape (m, n).\n",
    "        num_iters (int): Number of iterations to perform.\n",
    "    \n",
    "    Returns:\n",
    "        u (torch.Tensor): Dominant left singular vector (m,).\n",
    "        sigma (torch.Tensor): Dominant singular value (scalar).\n",
    "        v (torch.Tensor): Dominant right singular vector (n,).\n",
    "    \"\"\"\n",
    "    # Start with a random vector on the appropriate device\n",
    "    n = A.shape[1]\n",
    "    v = torch.randn(n, device=A.device)\n",
    "    v = v / torch.norm(v)\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "        # Multiply A*v\n",
    "        u = torch.mv(A, v)\n",
    "        u_norm = torch.norm(u)\n",
    "        if u_norm == 0:\n",
    "            break\n",
    "        u = u / u_norm\n",
    "        \n",
    "        # Multiply A^T*u\n",
    "        v = torch.mv(A.t(), u)\n",
    "        v_norm = torch.norm(v)\n",
    "        if v_norm == 0:\n",
    "            break\n",
    "        v = v / v_norm\n",
    "    \n",
    "    # Estimate the dominant singular value as ||A*v||\n",
    "    sigma = torch.norm(torch.mv(A, v))\n",
    "    # The left singular vector corresponding to sigma:\n",
    "    u = torch.mv(A, v) / sigma\n",
    "    return u, sigma, v\n",
    "\n",
    "def svd_abs(W):\n",
    "    Sg = W.sign()\n",
    "    Sg[Sg == 0] = 1\n",
    "    u, s, v = power_iteration(W.abs(), num_iters=5)\n",
    "    apx = s * torch.ger(u, v)\n",
    "    \n",
    "    return apx * Sg\n",
    "\n",
    "def find_other2(A, W, nnz, Z, U, print_sc=None, debug=False, reg=0, rho_start=0.03, iters=3, prune_iters=1, flip=False, final=False):\n",
    "    XX = A.T.matmul(A)\n",
    "    XX += torch.diag(torch.ones_like(XX.diag())) * XX.diag().mean() * reg\n",
    "    \n",
    "    #norm2 = torch.ones_like(norm2)\n",
    "    Wnn = W# * norm2.unsqueeze(1)\n",
    "    rho = 1\n",
    "    XY = A.T.matmul(Wnn)\n",
    "    XXinv = torch.inverse(XX + torch.eye(XX.shape[1], device=XX.device)*rho)\n",
    "    XXinv2 = torch.inverse(XX + torch.eye(XX.shape[1], device=XX.device)*rho_start)\n",
    "    U = U\n",
    "    Z = Z\n",
    "    \n",
    "    B = XXinv2.matmul(XY + rho_start*(Z-U))\n",
    "    \n",
    "    r_scale = c_scale = mask = None\n",
    "\n",
    "    for itt in range(iters-1):\n",
    "        Z = svd_abs(B+U)\n",
    "        #print(\"   \", \"z\", itt, (A.matmul(Z) - W).square().sum().item(), W.square().sum().item())\n",
    "\n",
    "        U = U + (B - Z)    \n",
    "\n",
    "        B = XXinv.matmul(XY + rho*(Z-U))\n",
    "\n",
    "    Z = svd_abs(B+U)\n",
    "    #print(\"   \", \"z\", iters-1, (A.matmul(Z) - W).square().sum().item(), W.square().sum().item())\n",
    "    U = U + (B - Z)\n",
    "   \n",
    "    return (Z), U\n",
    "\n",
    "\n",
    "def factorizeT(W, XX, o_norm, asp=0.16, sp=0.16, iters=80):\n",
    "    nza = int(W.shape[0]**2 * asp)\n",
    "    nzb = int(W.numel() * sp - nza)\n",
    "    \n",
    "    norm = XX.sqrt().unsqueeze(1) + 1e-8\n",
    "    norm_o = o_norm.sqrt() + 1e-8\n",
    "       \n",
    "    Wn = W * norm * norm_o\n",
    "       \n",
    "    mid = int(1.5*(W.shape[0]*W.shape[1]) / (W.shape[0] + W.shape[1]))\n",
    "    \n",
    "    Az = torch.randn((W.shape[0], mid), device=W.device)\n",
    "    Au = torch.zeros_like(Az)\n",
    "\n",
    "    Bz = torch.randn((mid, W.shape[1]), device=W.device)\n",
    "    Bu = torch.zeros_like(Bz)\n",
    "    \n",
    "    for itt in range(iters):\n",
    "        #if itt < 10:\n",
    "        #    rho_start = 0.0\n",
    "        #elif itt < 15:\n",
    "        #    rho_start = 0.00\n",
    "        #else:\n",
    "        #    rho_start = 0.1\n",
    "        rho_start = min(1.0, itt / (iters-3))**3\n",
    "        if True or itt > iters // 2:\n",
    "            nzaa = nza\n",
    "            nzbb = nzb\n",
    "        else:\n",
    "            alph = (itt / (iters // 2))**2\n",
    "            nzaa = int(nza / 2 * (1-alph) + nza * alph)\n",
    "            nzbb = int(nzb / 2 * (1-alph) + nzb * alph)\n",
    "\n",
    "            \n",
    "        mid = Bz.norm(dim=1) + 1e-12\n",
    "        final = itt == iters - 1\n",
    "        \n",
    "        Az, Au = (x.T for x in find_other2(Bz.T / mid, Wn.T, nzaa, Az.T, Au.T, reg=3e-2, debug=False, rho_start=rho_start, flip=True, final=final))\n",
    "        mid = Az.norm(dim=0) + 1e-12\n",
    "        Bz, Bu = find_other2(Az / mid, Wn, nzbb, Bz, Bu, reg=3e-2, debug=False, rho_start=rho_start, final=final)\n",
    "        #print(\"err\", itt, ((Az / mid).matmul(Bz) - Wn).square().sum().item(), (Wn).square().sum().item())\n",
    "        if itt == iters - 1:\n",
    "            print(\"err\", itt, ((Az / mid).matmul(Bz) - Wn).square().sum().item(), (Wn).square().sum().item())\n",
    "            \n",
    "    return ((Az / norm).matmul(Bz / norm_o)).T, (Bz / norm_o).T, (Az / norm).T, 1 / mid\n",
    "\n",
    "\n",
    "def factorizef(W, XX, o_norm, asp=0.16, sp=0.16, iters=80, l_prev=None):\n",
    "    s_time = time.time()\n",
    "    if W.shape[0] >= W.shape[1]:\n",
    "        return factorizeT(W.T, XX, o_norm, asp, sp=sp, iters=iters)\n",
    "    \n",
    "    #print(\"a\")\n",
    "    nza = int(W.shape[0]**2 * asp)\n",
    "    nzb = int(W.numel() * sp - nza)\n",
    "    norm = XX.sqrt() + 1e-8\n",
    "    norm_o = (o_norm.sqrt() + 1e-8).unsqueeze(1)\n",
    "\n",
    "    Wn = W * norm * norm_o\n",
    "    mid = int(1.5*(W.shape[0]*W.shape[1]) / (W.shape[0] + W.shape[1]))\n",
    "    \n",
    "    Az = torch.randn((W.shape[0], mid), device=W.device)\n",
    "    Au = torch.zeros_like(Az)\n",
    "\n",
    "    Bz = torch.randn((mid, W.shape[1]), device=W.device)\n",
    "    Bu = torch.zeros_like(Bz)\n",
    "    \n",
    "    for itt in range(iters):\n",
    "        #if itt < 10:\n",
    "        #    rho_start = 0.0\n",
    "        #elif itt < 15:\n",
    "        #    rho_start = 0.00\n",
    "        #else:\n",
    "        #    rho_start = 0.1\n",
    "            \n",
    "        rho_start = min(1.0, itt / (iters-3))**3\n",
    "        if True or itt > iters // 2:\n",
    "            nzaa = nza\n",
    "            nzbb = nzb\n",
    "        else:\n",
    "            alph = (itt / (iters // 2))**2\n",
    "            nzaa = int(nza / 2 * (1-alph) + nza * alph)\n",
    "            nzbb = int(nzb / 2 * (1-alph) + nzb * alph)\n",
    "            \n",
    "        \n",
    "        final = itt == iters - 1\n",
    "        mid = Bz.norm(dim=1) + 1e-12\n",
    "        Az, Au = (x.T for x in find_other2(Bz.T / mid, Wn.T, nzaa, Az.T, Au.T, reg=3e-2, debug=False, rho_start=rho_start, final=final))        \n",
    "        mid = Az.norm(dim=0) + 1e-12\n",
    "        Bz, Bu = find_other2(Az / mid, Wn, nzbb, Bz, Bu, reg=3e-2, debug=False, rho_start=rho_start, flip=True, final=final)\n",
    "        #print(\"err\", itt, ((Az / mid).matmul(Bz) - Wn).square().sum().item(), (Wn).square().sum().item())\n",
    "        #print(itt, time.time() - s_time, end =\" \") \n",
    "        #print_scores(Az.matmul(Bz / norm))\n",
    "        if itt == iters - 1:\n",
    "            print(\"err\", itt, ((Az / mid).matmul(Bz) - Wn).square().sum().item(), (Wn).square().sum().item())\n",
    "            \n",
    "    return (Az / norm_o).matmul(Bz / norm), Az / norm_o, Bz / norm, 1 / mid\n",
    "\n",
    "def factorize(lx, l_prev=None):\n",
    "    W = lx.weight.detach().float()\n",
    "    \n",
    "    sm = min(W.shape)\n",
    "    lg = max(W.shape)\n",
    "    mid = sm\n",
    "    print(\"mid\", mid)\n",
    "    lim = 1.25\n",
    "    for density in np.linspace(0.1, 0.4, 301):\n",
    "        total_size = 0\n",
    "        total_pars = 0\n",
    "        total_pars += sm*lg\n",
    "        mask_size = sm*mid + mid*lg\n",
    "        total_ones2 = sm*lg * density\n",
    "        p=total_ones2 / mask_size\n",
    "        ent = -p*np.log2(p)-(1-p)*np.log2(1-p)\n",
    "        total_size += (total_ones2*2 + mask_size*ent)\n",
    "        #print(\" \", density, total_size / total_pars)\n",
    "        if total_size / total_pars < lim:\n",
    "            sp = density\n",
    "    \n",
    "    \n",
    "    if W.shape[0] == W.shape[1]:\n",
    "        asp = sp/2\n",
    "    else:\n",
    "        asp = sp\n",
    "    W2, Ab, Bb, mid = factorizef(W, lx.i_norm, lx.o_norm, asp=asp, sp=sp, l_prev=l_prev, iters=260)\n",
    "    Ac = Ab\n",
    "    \n",
    "    #Ac = Ab\n",
    "    #W3 = Ac.matmul(Bb)\n",
    "    \n",
    "    #Bc = get_at(lx.XX, W.T, Bb.T, Ac.T).T\n",
    "    Bc = Bb\n",
    "    \n",
    "    An = Ac.norm() + 1e-12\n",
    "    Bn = Bc.norm() + 1e-12\n",
    "    Ac *= (Bn/An).sqrt()\n",
    "    Bc *= (An/Bn).sqrt()\n",
    "    \n",
    "    W3 = (Ac * mid).matmul(Bc)\n",
    "    assert W3.shape == lx.weight.shape\n",
    "    print(\"sparsity check\", ((Ac != 0).sum() + (Bb != 0).sum()).item() / W3.numel())\n",
    "    return W3, Ac, Bc, mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18157288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...\n",
      "Ready.\n",
      "0 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.004409150220453739 752.152099609375\n",
      "sparsity check 1.5\n",
      "err_spxsp 739.8961181640625\n",
      "0 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.08861272037029266 68.85771942138672\n",
      "sparsity check 1.5\n",
      "err_spxsp 453.7467346191406\n",
      "0 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.33225464820861816 1009.7816162109375\n",
      "sparsity check 1.5\n",
      "err_spxsp 168.20858764648438\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.00012030465134671431\n",
      "0 0.0007127402209334832\n",
      "1 9.785382823679356e-05\n",
      "2 0.00010728504642543157\n",
      "3 4.880300822662775e-05\n",
      "err after  4.5220203190865504e-05\n",
      "0 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.0016098590567708015 53.869529724121094\n",
      "sparsity check 1.5\n",
      "err_spxsp 462.95745849609375\n",
      "0 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.2648067474365234 107.59297180175781\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 1951.2239990234375\n",
      "0 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.0980174541473389 137.4292449951172\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 1921.998779296875\n",
      "0 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.017139434814453 208.99072265625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2469.73388671875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.4049861120147398\n",
      "0 0.09304106577656057\n",
      "1 0.1010041749004813\n",
      "2 0.2222950009345368\n",
      "3 0.0746340804207648\n",
      "err after  0.05172908311124047\n",
      "1 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.1893714815378189 578.8002319335938\n",
      "sparsity check 1.5\n",
      "err_spxsp 1272.84423828125\n",
      "1 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.7662174701690674 164.64341735839844\n",
      "sparsity check 1.5\n",
      "err_spxsp 449.21063232421875\n",
      "1 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.646923065185547 543.45947265625\n",
      "sparsity check 1.5\n",
      "err_spxsp 174.91497802734375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.1018477320594684\n",
      "0 0.09013049159511866\n",
      "1 0.07087062471237005\n",
      "2 0.06183008852895\n",
      "3 0.05895432984925719\n",
      "err after  0.05880072193849628\n",
      "1 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.1650686115026474 1053.642333984375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1208.1943359375\n",
      "1 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.824145317077637 107.7333984375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2175.7763671875\n",
      "1 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.7010722160339355 85.03993225097656\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2080.53466796875\n",
      "1 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 57.942787170410156 5135751.0\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3503.42333984375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.17474653977842536\n",
      "0 0.16815546670841286\n",
      "1 0.16158481952152215\n",
      "2 0.159411243370414\n",
      "3 0.15768614040644024\n",
      "err after  0.15666171858538291\n",
      "2 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.1670143604278564 156.05548095703125\n",
      "sparsity check 1.5\n",
      "err_spxsp 1538.11572265625\n",
      "2 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 933.5416259765625 8366.56640625\n",
      "sparsity check 1.5\n",
      "err_spxsp 616.27490234375\n",
      "2 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 19.63437843322754 183.68228149414062\n",
      "sparsity check 1.5\n",
      "err_spxsp 685.9356079101562\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.16706125056225574\n",
      "0 0.1651680948707508\n",
      "1 0.16220488581893733\n",
      "2 0.16088139922067057\n",
      "3 0.16048827612394234\n",
      "err after  0.16044908346884768\n",
      "2 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.266258955001831 328.5715637207031\n",
      "sparsity check 1.5\n",
      "err_spxsp 1562.36865234375\n",
      "2 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 28.492717742919922 193.29612731933594\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2392.61083984375\n",
      "2 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 21.219341278076172 160.72035217285156\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2498.617431640625\n",
      "2 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 52.074378967285156 358.48919677734375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2678.966796875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.3119358629191993\n",
      "0 0.30420744941511657\n",
      "1 0.29767563233326655\n",
      "2 0.2569496373689617\n",
      "3 0.22864456119714305\n",
      "err after  0.2284800533670932\n",
      "3 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.043851852416992 272.73956298828125\n",
      "sparsity check 1.5\n",
      "err_spxsp 1779.390625\n",
      "3 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1429.1253662109375 10808.3203125\n",
      "sparsity check 1.5\n",
      "err_spxsp 563.0208740234375\n",
      "3 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 21.00092124938965 279.1143798828125\n",
      "sparsity check 1.5\n",
      "err_spxsp 583.3409423828125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.2547434716980206\n",
      "0 0.24265110419946723\n",
      "1 0.23494548910093727\n",
      "err 259 32.713539123535156 226.85885620117188\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2860.935791015625\n",
      "3 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 54.939964294433594 395.2703857421875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2546.64599609375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.06040167099854443\n",
      "0 0.0560417422093451\n",
      "1 0.05024362598487642\n",
      "2 0.047855975695711095\n",
      "3 0.04714846338174539\n",
      "err after  0.047076833303435706\n",
      "4 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.2502427101135254 275.4961242675781\n",
      "sparsity check 1.5\n",
      "err_spxsp 1899.656982421875\n",
      "4 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 827.5723876953125 5921.1376953125\n",
      "sparsity check 1.5\n",
      "err_spxsp 627.156005859375\n",
      "4 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 26.394500732421875 227.90928649902344\n",
      "sparsity check 1.5\n",
      "err_spxsp 644.4097900390625\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.056093376624630764\n",
      "0 0.05365824249747675\n",
      "1 0.0505475585887325\n",
      "2 0.04926281427469803\n",
      "3 0.04885362226923462\n",
      "err after  0.04881436959840357\n",
      "4 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.4463372230529785 382.02532958984375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1931.76123046875\n",
      "4 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 41.00659942626953 294.8365783691406\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2571.048828125\n",
      "4 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 32.78742218017578 317.58233642578125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2988.217529296875\n",
      "4 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 55.32447052001953 396.3924255371094\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2467.0146484375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.049979240327957086\n",
      "0 0.0466084443469299\n",
      "1 0.04249659452034393\n",
      "2 0.040648372763826046\n",
      "3 0.04006959102116525\n",
      "err after  0.04001247774431249\n",
      "5 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.3693747520446777 230.21742248535156\n",
      "sparsity check 1.5\n",
      "err_spxsp 2008.6170654296875\n",
      "5 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 539.2037963867188 3735.19921875\n",
      "sparsity check 1.5\n",
      "err_spxsp 657.0899047851562\n",
      "5 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 22.500003814697266 205.96139526367188\n",
      "sparsity check 1.5\n",
      "err_spxsp 690.9976806640625\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.047483747111982666\n",
      "0 0.04565162042854354\n",
      "1 0.04324181064293953\n",
      "2 0.042193651279376354\n",
      "3 0.041851208843581844\n",
      "err after  0.0418176333187148\n",
      "5 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.4526920318603516 366.24542236328125\n",
      "sparsity check 1.5\n",
      "err_spxsp 2111.62353515625\n",
      "5 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 40.32505798339844 258.5774841308594\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2546.61669921875\n",
      "5 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err 259 30.30474281311035 230.8680419921875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2958.1650390625\n",
      "5 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 48.445682525634766 303.79119873046875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2416.36865234375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.0432671194721479\n",
      "0 0.040346340465475805\n",
      "1 0.037100409346749075\n",
      "2 0.03568293400894618\n",
      "3 0.03520862512959866\n",
      "err after  0.0351554329827195\n",
      "6 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.6736128330230713 217.57708740234375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1642.927001953125\n",
      "6 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 335.97003173828125 2571.9736328125\n",
      "sparsity check 1.5\n",
      "err_spxsp 550.1970825195312\n",
      "6 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 18.654781341552734 158.19082641601562\n",
      "sparsity check 1.5\n",
      "err_spxsp 547.31884765625\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04024686032789759\n",
      "0 0.03898274608218344\n",
      "1 0.03723682901909342\n",
      "2 0.036414732014236506\n",
      "3 0.03613105067779543\n",
      "err after  0.036102136415138375\n",
      "6 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.602108478546143 354.7065734863281\n",
      "sparsity check 1.5\n",
      "err_spxsp 1709.3270263671875\n",
      "6 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 38.763763427734375 251.05921936035156\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2514.859375\n",
      "6 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 27.921119689941406 207.30792236328125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3002.816650390625\n",
      "6 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 43.24871063232422 273.6418762207031\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2366.018798828125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.041668655481771566\n",
      "0 0.03886188528849743\n",
      "1 0.03609704516566126\n",
      "2 0.03485913972690469\n",
      "3 0.03444645819399739\n",
      "err after  0.034402726938424166\n",
      "7 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.051452159881592 164.6795196533203\n",
      "sparsity check 1.5\n",
      "err_spxsp 1573.974365234375\n",
      "7 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 246.86611938476562 1991.294189453125\n",
      "sparsity check 1.5\n",
      "err_spxsp 566.3046875\n",
      "7 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 17.396068572998047 150.14663696289062\n",
      "sparsity check 1.5\n",
      "err_spxsp 590.9596557617188\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.03868057474028319\n",
      "0 0.03771160488395253\n",
      "1 0.03629572889622068\n",
      "2 0.035573038629081566\n",
      "3 0.03532021676073782\n",
      "err after  0.03529427018656861\n",
      "7 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.758176326751709 281.454345703125\n",
      "sparsity check 1.5\n",
      "err_spxsp 1594.7125244140625\n",
      "7 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 35.63901901245117 232.78787231445312\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2507.919921875\n",
      "7 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 25.183990478515625 186.66680908203125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2952.43408203125\n",
      "7 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 39.329124450683594 251.73580932617188\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2341.5341796875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04258144997584168\n",
      "0 0.03987357851292472\n",
      "1 0.03719618653849466\n",
      "2 0.0360049113369314\n",
      "3 0.03561141608952312\n",
      "err after  0.03556880862015532\n",
      "8 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.9072675704956055 152.6087646484375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1679.552490234375\n",
      "8 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 171.38980102539062 1393.1416015625\n",
      "sparsity check 1.5\n",
      "err_spxsp 585.1640625\n",
      "8 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 18.540332794189453 157.43093872070312\n",
      "sparsity check 1.5\n",
      "err_spxsp 633.5721435546875\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.03975642072327901\n",
      "0 0.0388917797972681\n",
      "1 0.03755804445972899\n",
      "2 0.03687054377223831\n",
      "3 0.03662984362745192\n",
      "err after  0.03660499850229826\n",
      "8 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.4087305068969727 301.6839599609375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1756.7110595703125\n",
      "8 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.131196975708008 205.34866333007812\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2544.162109375\n",
      "8 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 22.24335479736328 163.93756103515625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2837.26416015625\n",
      "8 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 35.5601806640625 228.40982055664062\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2365.760498046875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04517114124610089\n",
      "0 0.042633159304386936\n",
      "1 0.04011879155586939\n",
      "2 0.03898090373695595\n",
      "3 0.03860218219051603\n",
      "err after  0.03856034483760595\n",
      "9 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.376875877380371 129.83160400390625\n",
      "sparsity check 1.5\n",
      "err_spxsp 1720.5340576171875\n",
      "9 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 146.47059631347656 1206.7689208984375\n",
      "sparsity check 1.5\n",
      "err_spxsp 610.2018432617188\n",
      "9 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 19.067420959472656 152.9351806640625\n",
      "sparsity check 1.5\n",
      "err_spxsp 668.1661376953125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04264289769344032\n",
      "0 0.041901063043042086\n",
      "1 0.0406697056023404\n",
      "2 0.04000065075524617\n",
      "3 0.03976472331851255\n",
      "err after  0.039740378051646985\n",
      "9 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.788684606552124 284.533203125\n",
      "sparsity check 1.5\n",
      "err_spxsp 1782.8369140625\n",
      "9 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 27.39826774597168 198.32470703125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2567.82763671875\n",
      "9 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 19.765453338623047 147.06204223632812\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2787.802734375\n",
      "9 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 32.97407150268555 210.6680908203125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2398.15771484375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04826711738132872\n",
      "0 0.04570688621606678\n",
      "1 0.04302497752360068\n",
      "2 0.04183531668240903\n",
      "3 0.041442305155214854\n",
      "err after  0.04139970851247199\n",
      "10 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.127183437347412 116.02481842041016\n",
      "sparsity check 1.5\n",
      "err_spxsp 1596.641357421875\n",
      "10 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 89.4788818359375 716.9910888671875\n",
      "sparsity check 1.5\n",
      "err_spxsp 581.0660400390625\n",
      "10 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 21.145490646362305 169.0566864013672\n",
      "sparsity check 1.5\n",
      "err_spxsp 598.7122802734375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04578317668347154\n",
      "0 0.044956689001992345\n",
      "1 0.04369563507498242\n",
      "2 0.04301871314964956\n",
      "3 0.042778067116159946\n",
      "err after  0.04275327350478619\n",
      "10 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.384402275085449 270.76123046875\n",
      "sparsity check 1.5\n",
      "err_spxsp 1677.837646484375\n",
      "10 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 25.583881378173828 173.49679565429688\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2620.750244140625\n",
      "10 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 18.30300521850586 138.4849853515625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2776.713134765625\n",
      "10 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 32.31189727783203 205.8499755859375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2418.005859375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04808170745673124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.045930181950097904\n",
      "1 0.04347387212328613\n",
      "2 0.04234333791100653\n",
      "3 0.04196310954284854\n",
      "err after  0.04192239584517665\n",
      "11 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.9723095893859863 123.39998626708984\n",
      "sparsity check 1.5\n",
      "err_spxsp 1355.6492919921875\n",
      "11 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 97.81748962402344 836.0361938476562\n",
      "sparsity check 1.5\n",
      "err_spxsp 621.506103515625\n",
      "11 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 18.541027069091797 152.54336547851562\n",
      "sparsity check 1.5\n",
      "err_spxsp 629.8184814453125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04552018687536474\n",
      "0 0.04487935485667549\n",
      "1 0.043796509176900145\n",
      "2 0.04316287765686866\n",
      "3 0.042932970565743744\n",
      "err after  0.042909065436106175\n",
      "11 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.266900062561035 279.3551025390625\n",
      "sparsity check 1.5\n",
      "err_spxsp 1409.083251953125\n",
      "11 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 24.404796600341797 163.05703735351562\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2647.01123046875\n",
      "11 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 17.25922393798828 126.27268981933594\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2729.49560546875\n",
      "11 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.351131439208984 197.3453826904297\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2478.7490234375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04943459227797575\n",
      "0 0.04754573780519422\n",
      "1 0.04531754297204316\n",
      "2 0.044231703141122125\n",
      "3 0.0438625042734202\n",
      "err after  0.043822042454849\n",
      "12 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.1274242401123047 105.49398803710938\n",
      "sparsity check 1.5\n",
      "err_spxsp 1616.405517578125\n",
      "12 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 86.46846008300781 717.9093627929688\n",
      "sparsity check 1.5\n",
      "err_spxsp 634.494384765625\n",
      "12 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 19.043964385986328 142.8334197998047\n",
      "sparsity check 1.5\n",
      "err_spxsp 662.677001953125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.04726143859443255\n",
      "0 0.04674899758538231\n",
      "1 0.04576734638249036\n",
      "2 0.04514715410186909\n",
      "3 0.044919516119989567\n",
      "err after  0.04489576081687119\n",
      "12 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.148472547531128 230.62864685058594\n",
      "sparsity check 1.5\n",
      "err_spxsp 1646.912109375\n",
      "12 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 24.21173858642578 160.55667114257812\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2685.000244140625\n",
      "12 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 17.42389488220215 125.05581665039062\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2703.00146484375\n",
      "12 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.340591430664062 196.6032257080078\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2526.796630859375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.052844241057755426\n",
      "0 0.05073467693000566\n",
      "1 0.048337586980778724\n",
      "2 0.04717860635719262\n",
      "3 0.04678371431509731\n",
      "err after  0.04673975174955558\n",
      "13 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.000629425048828 95.82095336914062\n",
      "sparsity check 1.5\n",
      "err_spxsp 1604.593017578125\n",
      "13 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 89.30386352539062 683.808349609375\n",
      "sparsity check 1.5\n",
      "err_spxsp 717.870361328125\n",
      "13 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 18.360694885253906 141.0018310546875\n",
      "sparsity check 1.5\n",
      "err_spxsp 697.405517578125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.05070489003264811\n",
      "0 0.050036585991620086\n",
      "1 0.04884177297935821\n",
      "2 0.048159176207263954\n",
      "3 0.04791140861925669\n",
      "err after  0.047885568797937594\n",
      "13 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.4529528617858887 211.34793090820312\n",
      "sparsity check 1.5\n",
      "err_spxsp 1663.36962890625\n",
      "13 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 25.428783416748047 180.03509521484375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2775.407470703125\n",
      "13 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 18.271072387695312 131.2931671142578\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2724.08154296875\n",
      "13 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 34.91523361206055 219.1702423095703\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2629.67041015625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.055720772259519435\n",
      "0 0.053904552856693044\n",
      "1 0.05147214354656171\n",
      "2 0.05023498646914959\n",
      "3 0.04980960991815664\n",
      "err after  0.049764767129090615\n",
      "14 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.888960838317871 88.76974487304688\n",
      "sparsity check 1.5\n",
      "err_spxsp 1495.717529296875\n",
      "14 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 71.74061584472656 518.4655151367188\n",
      "sparsity check 1.5\n",
      "err_spxsp 670.2655029296875\n",
      "14 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 19.94577980041504 147.13839721679688\n",
      "sparsity check 1.5\n",
      "err_spxsp 659.6249389648438\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.05347553016326856\n",
      "0 0.05297616761527024\n",
      "1 0.05190986016532406\n",
      "2 0.05120225432619918\n",
      "3 0.05094128291239031\n",
      "err after  0.05091412209731061\n",
      "14 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.9106504917144775 198.26678466796875\n",
      "sparsity check 1.5\n",
      "err_spxsp 1534.3155517578125\n",
      "14 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 25.835424423217773 170.49844360351562\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2755.23291015625\n",
      "14 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 19.180843353271484 134.4981689453125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2694.73876953125\n",
      "14 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 36.54788589477539 229.28079223632812\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2658.0859375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.06169213457906153\n",
      "0 0.05950843944447115\n",
      "1 0.05680527388176415\n",
      "2 0.05544287465454545\n",
      "3 0.0549747582845157\n",
      "err after  0.05492533795768395\n",
      "15 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.3136117458343506 105.02214050292969\n",
      "sparsity check 1.5\n",
      "err_spxsp 1553.54541015625\n",
      "15 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 80.60279083251953 567.7225341796875\n",
      "sparsity check 1.5\n",
      "err_spxsp 734.3744506835938\n",
      "15 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 20.427616119384766 143.36312866210938\n",
      "sparsity check 1.5\n",
      "err_spxsp 722.359130859375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.058927436111844145\n",
      "0 0.058345255310996436\n",
      "1 0.05714441249438096\n",
      "2 0.05637039913563058\n",
      "3 0.05608322507760022\n",
      "err after  0.05605359736364335\n",
      "15 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.1905720233917236 213.80062866210938\n",
      "sparsity check 1.5\n",
      "err_spxsp 1618.97265625\n",
      "15 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 28.418682098388672 190.3063201904297\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2833.84375\n",
      "15 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 21.456865310668945 157.09695434570312\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2767.664306640625\n",
      "15 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 42.125770568847656 262.15301513671875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2756.79052734375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.06933785833825823\n",
      "0 0.06752194270666223\n",
      "1 0.06473141223250423\n",
      "2 0.0631570704135811\n",
      "3 0.06260836991714314\n",
      "err after  0.06255110891652294\n",
      "16 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.9261245727539062 85.55134582519531\n",
      "sparsity check 1.5\n",
      "err_spxsp 1509.404052734375\n",
      "16 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 76.11387634277344 502.17926025390625\n",
      "sparsity check 1.5\n",
      "err_spxsp 824.391845703125\n",
      "16 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err 259 25.187938690185547 164.2322540283203\n",
      "sparsity check 1.5\n",
      "err_spxsp 841.9446411132812\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.06867638307448942\n",
      "0 0.06787234552029986\n",
      "1 0.06609507701068651\n",
      "2 0.0650461425393587\n",
      "3 0.06467917183181271\n",
      "err after  0.06464169474202208\n",
      "16 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.8238954544067383 187.89117431640625\n",
      "sparsity check 1.5\n",
      "err_spxsp 1551.6990966796875\n",
      "16 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 30.225692749023438 211.69622802734375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2793.68310546875\n",
      "16 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 23.28314208984375 158.19570922851562\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2762.76904296875\n",
      "16 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 50.88172912597656 316.85101318359375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2803.765380859375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.07886043426697142\n",
      "0 0.07728412862343248\n",
      "1 0.07455369875242468\n",
      "2 0.07290375715820119\n",
      "3 0.07231290034542326\n",
      "err after  0.07225233748613391\n",
      "17 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.608250141143799 72.10149383544922\n",
      "sparsity check 1.5\n",
      "err_spxsp 1644.568359375\n",
      "17 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 89.93759155273438 561.5076904296875\n",
      "sparsity check 1.5\n",
      "err_spxsp 831.5830078125\n",
      "17 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 17.22021484375 108.77345275878906\n",
      "sparsity check 1.5\n",
      "err_spxsp 866.96142578125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.07601149490801618\n",
      "0 0.07559515433968045\n",
      "1 0.07431656944390852\n",
      "2 0.07335360803699587\n",
      "3 0.07298434547556099\n",
      "err after  0.07294571731472388\n",
      "17 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.684086322784424 130.696533203125\n",
      "sparsity check 1.5\n",
      "err_spxsp 1648.9552001953125\n",
      "17 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.90174102783203 200.03689575195312\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2748.25537109375\n",
      "17 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 25.16921615600586 164.36073303222656\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2796.663330078125\n",
      "17 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 52.029396057128906 313.80963134765625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2777.004150390625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.08937714605417568\n",
      "0 0.08770119100518059\n",
      "1 0.08490310446359217\n",
      "2 0.0831519189523533\n",
      "3 0.08251879415183794\n",
      "err after  0.0824531393009238\n",
      "18 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.579498291015625 68.4173812866211\n",
      "sparsity check 1.5\n",
      "err_spxsp 1643.524169921875\n",
      "18 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 113.020751953125 693.6233520507812\n",
      "sparsity check 1.5\n",
      "err_spxsp 914.7669677734375\n",
      "18 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 17.830053329467773 112.63856506347656\n",
      "sparsity check 1.5\n",
      "err_spxsp 958.2572021484375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.08664822333958\n",
      "0 0.0861605565296486\n",
      "1 0.08476684603374451\n",
      "2 0.08372951670025941\n",
      "3 0.08332905938732438\n",
      "err after  0.08328699557750951\n",
      "18 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.830915927886963 117.92819213867188\n",
      "sparsity check 1.5\n",
      "err_spxsp 1672.563232421875\n",
      "18 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 34.05816650390625 210.990478515625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2758.31298828125\n",
      "18 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 27.773662567138672 176.76382446289062\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2875.244873046875\n",
      "18 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 53.601139068603516 331.5858459472656\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2792.40478515625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.10017792013240978\n",
      "0 0.09873839642386883\n",
      "1 0.09597046874114312\n",
      "2 0.09418211708543822\n",
      "3 0.09353299169742968\n",
      "err after  0.09346638232818805\n",
      "19 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.2100727558135986 59.683990478515625\n",
      "sparsity check 1.5\n",
      "err_spxsp 1541.6348876953125\n",
      "19 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 100.2984619140625 624.4947509765625\n",
      "sparsity check 1.5\n",
      "err_spxsp 908.62451171875\n",
      "19 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 14.612325668334961 89.57666778564453\n",
      "sparsity check 1.5\n",
      "err_spxsp 970.455810546875\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.09680994407972321\n",
      "0 0.09641655506857205\n",
      "1 0.09511018774355762\n",
      "2 0.09406179626239464\n",
      "3 0.09364943770924583\n",
      "err after  0.09360613882017788\n",
      "19 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.2179794311523438 103.16838836669922\n",
      "sparsity check 1.5\n",
      "err_spxsp 1525.8399658203125\n",
      "19 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 34.312522888183594 212.47113037109375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2758.51025390625\n",
      "19 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.328359603881836 184.57431030273438\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2913.370361328125\n",
      "19 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 52.01808547973633 321.6010437011719\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2815.111328125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.11188419885002077\n",
      "0 0.11052543632104062\n",
      "1 0.10762991261435673\n",
      "2 0.10571355954743922\n",
      "3 0.10501447622664273\n",
      "err after  0.10494255440426059\n",
      "20 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.7521569728851318 48.494163513183594\n",
      "sparsity check 1.5\n",
      "err_spxsp 1511.0078125\n",
      "20 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 93.12989807128906 543.120849609375\n",
      "sparsity check 1.5\n",
      "err_spxsp 942.4111328125\n",
      "20 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 15.354126930236816 97.2686538696289\n",
      "sparsity check 1.5\n",
      "err_spxsp 1056.0205078125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.10903618548763916\n",
      "0 0.10852001805324107\n",
      "1 0.10690142188104801\n",
      "2 0.10573650669539347\n",
      "3 0.10528628432075493\n",
      "err after  0.10523866271250881\n",
      "20 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.796529769897461 83.31024169921875\n",
      "sparsity check 1.5\n",
      "err_spxsp 1487.07568359375\n",
      "20 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 33.95575714111328 207.85877990722656\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2731.8779296875\n",
      "20 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.590858459472656 186.36605834960938\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2934.5400390625\n",
      "20 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 55.39309310913086 343.87066650390625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2860.46240234375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12069440048071556\n",
      "0 0.11956166700110771\n",
      "1 0.11694906876073219\n",
      "2 0.11513981691678055\n",
      "3 0.11446812533540651\n",
      "err after  0.11439882926060818\n",
      "21 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.4856836795806885 38.58125686645508\n",
      "sparsity check 1.5\n",
      "err_spxsp 1420.4698486328125\n",
      "21 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 105.24041748046875 627.8526611328125\n",
      "sparsity check 1.5\n",
      "err_spxsp 989.052734375\n",
      "21 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 12.83413028717041 74.74166107177734\n",
      "sparsity check 1.5\n",
      "err_spxsp 1067.6527099609375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.11736183034372516\n",
      "0 0.11704762405133806\n",
      "1 0.11578536708839238\n",
      "2 0.11469605594174936\n",
      "3 0.11425604636315256\n",
      "err after  0.1142089759814553\n",
      "21 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.6484651565551758 73.31056213378906\n",
      "sparsity check 1.5\n",
      "err_spxsp 1420.461181640625\n",
      "21 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err 259 33.09438705444336 202.29519653320312\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2715.7568359375\n",
      "21 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.537734985351562 182.51339721679688\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2970.09326171875\n",
      "21 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 49.882469177246094 305.10113525390625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2845.36669921875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12797402220894583\n",
      "0 0.12688607737072743\n",
      "1 0.12433241028338671\n",
      "2 0.12253683808376081\n",
      "3 0.12185248135938309\n",
      "err after  0.1217829077213537\n",
      "22 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.9652419090270996 47.85017776489258\n",
      "sparsity check 1.5\n",
      "err_spxsp 1503.8101806640625\n",
      "22 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 95.46235656738281 562.497802734375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1026.648193359375\n",
      "22 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 13.638206481933594 81.26925659179688\n",
      "sparsity check 1.5\n",
      "err_spxsp 1081.295654296875\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12536088915658183\n",
      "0 0.1249531603534706\n",
      "1 0.12358014530036598\n",
      "2 0.12246789917116985\n",
      "3 0.122023743664613\n",
      "err after  0.12197626064880751\n",
      "22 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.1884427070617676 86.48100280761719\n",
      "sparsity check 1.5\n",
      "err_spxsp 1537.0382080078125\n",
      "22 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 32.4451904296875 195.2017822265625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2701.88671875\n",
      "22 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.26809310913086 179.6890106201172\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2999.48828125\n",
      "22 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 48.340511322021484 292.91168212890625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2828.77490234375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.1310388411511667\n",
      "0 0.13017299224156886\n",
      "1 0.12796517289825715\n",
      "2 0.12634617340518162\n",
      "3 0.12573050361243077\n",
      "err after  0.1256660287908744\n",
      "23 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.9703795909881592 42.03229522705078\n",
      "sparsity check 1.5\n",
      "err_spxsp 1586.6336669921875\n",
      "23 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 115.75757598876953 677.1477661132812\n",
      "sparsity check 1.5\n",
      "err_spxsp 1115.6177978515625\n",
      "23 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.414896965026855 66.32083892822266\n",
      "sparsity check 1.5\n",
      "err_spxsp 1173.2457275390625\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.128281819896074\n",
      "0 0.12799718775204383\n",
      "1 0.12682833490544\n",
      "2 0.12581047014100477\n",
      "3 0.1253988629905507\n",
      "err after  0.12535474079777487\n",
      "23 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.2785942554473877 72.67225646972656\n",
      "sparsity check 1.5\n",
      "err_spxsp 1576.944580078125\n",
      "23 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 32.127479553222656 191.3260040283203\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2740.61279296875\n",
      "23 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.678035736083984 180.89828491210938\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3028.719970703125\n",
      "23 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 42.76058578491211 260.5103759765625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2830.7685546875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.13299434015061706\n",
      "0 0.13225034627248533\n",
      "1 0.13017714099260047\n",
      "2 0.12860181322321296\n",
      "3 0.12800089587108232\n",
      "err after  0.12793806131230667\n",
      "24 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.644869089126587 42.769554138183594\n",
      "sparsity check 1.5\n",
      "err_spxsp 1336.1702880859375\n",
      "24 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 84.20677185058594 495.26666259765625\n",
      "sparsity check 1.5\n",
      "err_spxsp 1082.89794921875\n",
      "24 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.27191162109375 69.752685546875\n",
      "sparsity check 1.5\n",
      "err_spxsp 1186.61962890625\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.13048625268856995\n",
      "0 0.13024571386631578\n",
      "1 0.12920316273812205\n",
      "2 0.1282543991401326\n",
      "3 0.12786433784640394\n",
      "err after  0.12782223033718765\n",
      "24 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.7500523328781128 84.50798797607422\n",
      "sparsity check 1.5\n",
      "err_spxsp 1344.33154296875\n",
      "24 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.238460540771484 184.505126953125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2768.73291015625\n",
      "24 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.258399963378906 177.13616943359375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3059.11572265625\n",
      "24 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 38.360939025878906 235.90130615234375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2828.8037109375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.13102349851396866\n",
      "0 0.13028126160497777\n",
      "1 0.12844140725792386\n",
      "2 0.1270747509552166\n",
      "3 0.1265493938990403\n",
      "err after  0.12649455954669975\n",
      "25 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.827878475189209 39.541534423828125\n",
      "sparsity check 1.5\n",
      "err_spxsp 1476.3121337890625\n",
      "25 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 105.0147476196289 606.5947875976562\n",
      "sparsity check 1.5\n",
      "err_spxsp 1183.809814453125\n",
      "25 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.259933471679688 49.5019645690918\n",
      "sparsity check 1.5\n",
      "err_spxsp 1237.2681884765625\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12834654917242005\n",
      "0 0.12813459473545663\n",
      "1 0.12720598542364314\n",
      "2 0.12634730464196764\n",
      "3 0.125992935791146\n",
      "err after  0.12595459740259685\n",
      "25 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.2457447052001953 67.51180267333984\n",
      "sparsity check 1.5\n",
      "err_spxsp 1495.671630859375\n",
      "25 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.391887664794922 186.57513427734375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2818.181640625\n",
      "25 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.848108291625977 181.21755981445312\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3100.9794921875\n",
      "25 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 33.85667037963867 213.89013671875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2847.022705078125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.1292950379429385\n",
      "0 0.12854948444874026\n",
      "1 0.12673366605304182\n",
      "2 0.12536414412898012\n",
      "3 0.12483935704221949\n",
      "err after  0.12478460863349028\n",
      "26 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.8268864154815674 43.43778991699219\n",
      "sparsity check 1.5\n",
      "err_spxsp 1396.0\n",
      "26 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 79.84747314453125 506.97412109375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1219.939453125\n",
      "26 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.886617660522461 65.58378601074219\n",
      "sparsity check 1.5\n",
      "err_spxsp 1419.167236328125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12746641077683307\n",
      "0 0.12719701608875766\n",
      "1 0.12624795225565322\n",
      "2 0.12542231610859744\n",
      "3 0.12508198444265872\n",
      "err after  0.12504517936031334\n",
      "26 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.0753979682922363 77.22218322753906\n",
      "sparsity check 1.5\n",
      "err_spxsp 1396.61962890625\n",
      "26 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.24115562438965 186.35215759277344\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2868.322265625\n",
      "26 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.897254943847656 182.98776245117188\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3129.190673828125\n",
      "26 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.05125617980957 198.2025604248047\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2884.921630859375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err before 0.12477380456402898\n",
      "0 0.12402872546226718\n",
      "1 0.12240385514451191\n",
      "2 0.12123397222603671\n",
      "3 0.12077984315692447\n",
      "err after  0.12073273747228086\n",
      "27 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.900586485862732 31.112436294555664\n",
      "sparsity check 1.5\n",
      "err_spxsp 1638.91552734375\n",
      "27 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 81.98944091796875 470.7916259765625\n",
      "sparsity check 1.5\n",
      "err_spxsp 1255.4072265625\n",
      "27 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.767980575561523 50.41999053955078\n",
      "sparsity check 1.5\n",
      "err_spxsp 1373.919189453125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12260537582915276\n",
      "0 0.12235958231030963\n",
      "1 0.1215112112404313\n",
      "2 0.12076353532029316\n",
      "3 0.12045367987593636\n",
      "err after  0.12042019271757454\n",
      "27 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.4135220050811768 52.12244415283203\n",
      "sparsity check 1.5\n",
      "err_spxsp 1675.66943359375\n",
      "27 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.85646629333496 196.09344482421875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2943.57958984375\n",
      "27 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 30.65310287475586 193.83966064453125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3169.59033203125\n",
      "27 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.017099380493164 190.92141723632812\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 2950.98828125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12209370019263588\n",
      "0 0.12124885531375185\n",
      "1 0.11949959109188057\n",
      "2 0.1183031634427607\n",
      "3 0.11784439723123796\n",
      "err after  0.11779628359363414\n",
      "28 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.7829607725143433 36.324684143066406\n",
      "sparsity check 1.5\n",
      "err_spxsp 1569.9345703125\n",
      "28 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 73.9484634399414 442.6328125\n",
      "sparsity check 1.5\n",
      "err_spxsp 1343.613525390625\n",
      "28 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.595763206481934 55.87057113647461\n",
      "sparsity check 1.5\n",
      "err_spxsp 1493.1988525390625\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.11983845016220585\n",
      "0 0.11955950397532433\n",
      "1 0.11869868609937839\n",
      "2 0.11795433502993546\n",
      "3 0.11764522464363836\n",
      "err after  0.1176118598668836\n",
      "28 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.2841038703918457 76.24609375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1664.6915283203125\n",
      "28 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 30.621517181396484 205.04229736328125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3064.3916015625\n",
      "28 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 28.86847496032715 192.03704833984375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3155.568359375\n",
      "28 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 29.311172485351562 202.10360717773438\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3096.8876953125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12220380001235753\n",
      "0 0.12128209564252757\n",
      "1 0.11946714197983965\n",
      "2 0.1182619761384558\n",
      "3 0.11780066989012994\n",
      "err after  0.11775198459508829\n",
      "29 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.3464407920837402 24.92983627319336\n",
      "sparsity check 1.5\n",
      "err_spxsp 1359.214111328125\n",
      "29 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 52.2736930847168 307.9524230957031\n",
      "sparsity check 1.5\n",
      "err_spxsp 1334.476318359375\n",
      "29 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.93154239654541 44.1982307434082\n",
      "sparsity check 1.5\n",
      "err_spxsp 1455.814453125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.11950252132373862\n",
      "0 0.11922677693655714\n",
      "1 0.11841270790318958\n",
      "2 0.11768339507398196\n",
      "3 0.11737180795171298\n",
      "err after  0.11733812422608025\n",
      "29 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.5326669216156006 49.25227355957031\n",
      "sparsity check 1.5\n",
      "err_spxsp 1388.0982666015625\n",
      "29 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 30.593093872070312 240.1038818359375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3204.9619140625\n",
      "29 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 28.908693313598633 258.20684814453125\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3236.7490234375\n",
      "29 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 30.258487701416016 219.85052490234375\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3233.783203125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.13412864739075303\n",
      "0 0.1321958436165005\n",
      "1 0.12942469576955773\n",
      "2 0.12792798201553524\n",
      "3 0.12739620893262327\n",
      "err after  0.127337456215173\n",
      "30 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.3924431800842285 20.32263946533203\n",
      "sparsity check 1.5\n",
      "err_spxsp 1437.1016845703125\n",
      "30 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 61.187042236328125 356.57122802734375\n",
      "sparsity check 1.5\n",
      "err_spxsp 1438.8560791015625\n",
      "30 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.8625688552856445 49.46149444580078\n",
      "sparsity check 1.5\n",
      "err_spxsp 1641.84716796875\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.12939253062359057\n",
      "0 0.12890559175866656\n",
      "1 0.12789986506686546\n",
      "2 0.12707660600426607\n",
      "3 0.12672074511647224\n",
      "err after  0.12668006867170334\n",
      "30 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.6969246864318848 32.182212829589844\n",
      "sparsity check 1.5\n",
      "err_spxsp 1486.8375244140625\n",
      "30 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 33.404571533203125 342.50946044921875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3410.59375\n",
      "30 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 30.253177642822266 267.35009765625\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3373.9658203125\n",
      "30 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 36.59770202636719 936.73388671875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3404.94384765625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.33813610405195504\n",
      "0 0.2922057473915629\n",
      "1 0.26698505791136995\n",
      "2 0.2615249266382307\n",
      "3 0.2599366004578769\n",
      "err after  0.25973433774197474\n",
      "31 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.9688943028450012 16.550251007080078\n",
      "sparsity check 1.5\n",
      "err_spxsp 1387.4169921875\n",
      "31 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 20.58917808532715 127.75875854492188\n",
      "sparsity check 1.5\n",
      "err_spxsp 1188.7945556640625\n",
      "31 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.715476036071777 50.86646270751953\n",
      "sparsity check 1.5\n",
      "err_spxsp 1286.03662109375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.26630645809927955\n",
      "0 0.26302059867884964\n",
      "1 0.2593903196393512\n",
      "2 0.25691163836745545\n",
      "3 0.25594015524256974\n",
      "err after  0.25581465859431773\n",
      "31 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.005704641342163 20.180601119995117\n",
      "sparsity check 1.5\n",
      "err_spxsp 1467.08837890625\n",
      "31 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 38.01980209350586 609.0614624023438\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3834.96142578125\n",
      "31 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 31.781494140625 291.6717224121094\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3737.6728515625\n",
      "31 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 64.25970458984375 1422.5233154296875\n",
      "sparsity check 1.499721793241279\n",
      "err_spxsp 3657.4853515625\n",
      "total time 11379.684545993805\n"
     ]
    }
   ],
   "source": [
    "import cupy\n",
    "\n",
    "def my_pack(x):\n",
    "    x = (x == 1).to(torch.uint8)\n",
    "    out = torch.zeros((x.shape[0]//8), device=x.device, dtype=torch.uint8)\n",
    "    for i in range(8):\n",
    "        out += x[i::8] << (7 - i)\n",
    "    return out\n",
    "\n",
    "@torch.compile\n",
    "def my_unpack(x):\n",
    "    out = torch.zeros((x.shape[0], 8), device=x.device, dtype=torch.int8)\n",
    "    for i in range(8):\n",
    "        out[:,i] = (x >> (7 - i)) & 1\n",
    "    return out.flatten() * 2 - 1\n",
    "\n",
    "def power_iteration(A, num_iters=5):\n",
    "    \"\"\"\n",
    "    Performs power iteration to compute the top singular vectors and value.\n",
    "    \n",
    "    Arguments:\n",
    "        A (torch.Tensor): The input matrix of shape (m, n).\n",
    "        num_iters (int): Number of iterations to perform.\n",
    "    \n",
    "    Returns:\n",
    "        u (torch.Tensor): Dominant left singular vector (m,).\n",
    "        sigma (torch.Tensor): Dominant singular value (scalar).\n",
    "        v (torch.Tensor): Dominant right singular vector (n,).\n",
    "    \"\"\"\n",
    "    # Start with a random vector on the appropriate device\n",
    "    n = A.shape[1]\n",
    "    v = torch.randn(n, device=A.device)\n",
    "    v = v / torch.norm(v)\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "        # Multiply A*v\n",
    "        u = torch.mv(A, v)\n",
    "        u_norm = torch.norm(u)\n",
    "        if u_norm == 0:\n",
    "            break\n",
    "        u = u / u_norm\n",
    "        \n",
    "        # Multiply A^T*u\n",
    "        v = torch.mv(A.t(), u)\n",
    "        v_norm = torch.norm(v)\n",
    "        if v_norm == 0:\n",
    "            break\n",
    "        v = v / v_norm\n",
    "    \n",
    "    # Estimate the dominant singular value as ||A*v||\n",
    "    sigma = torch.norm(torch.mv(A, v))\n",
    "    # The left singular vector corresponding to sigma:\n",
    "    u = torch.mv(A, v) / sigma\n",
    "    return u, sigma, v\n",
    "\n",
    "def svd_abs2(W):\n",
    "    Sg = W.sign()\n",
    "    Sg[Sg == 0] = 1\n",
    "    u, s, v = power_iteration(W.abs(), num_iters=5)\n",
    "    apx = s * torch.ger(u, v)\n",
    "    \n",
    "    return u * s, Sg, v\n",
    "\n",
    "class BitLinear(nn.Module):\n",
    "    def __init__(self, b):\n",
    "        super().__init__()\n",
    "        \n",
    "        #u, b, v = svd_abs(w.float())\n",
    "        b_packed = my_pack(b.flatten())\n",
    "        self.shape = b.shape\n",
    "        #print(b)\n",
    "        #print(my_unpack(b_packed).reshape(b.shape))\n",
    "        \n",
    "        self.register_buffer(\"bp\", b_packed)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.matmul(my_unpack(self.bp).reshape(self.shape).T.to(x.dtype))\n",
    "        \n",
    "\n",
    "        \n",
    "class Mul(nn.Module):\n",
    "    def __init__(self, w):\n",
    "        super().__init__()\n",
    "        #print(\"w\", w.amin().item(), w.median().item(), w.amax().item())\n",
    "        \n",
    "        self.register_buffer(\"w\", w)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * self.w.to(x.dtype)\n",
    "        \n",
    "\n",
    "def replace(lx):\n",
    "    dev = \"cuda\"\n",
    "    m1 = lx.weight.B\n",
    "    m2 = lx.weight.A\n",
    "    \n",
    "    u1, b1, v1 = svd_abs2(m1.float())\n",
    "    u2, b2, v2 = svd_abs2(m2.float())\n",
    "    \n",
    "    lx2 = nn.Sequential(\n",
    "        Mul(v1),\n",
    "        BitLinear(b1),\n",
    "        Mul(u1*lx.weight.mid*v2),\n",
    "        BitLinear(b2),\n",
    "        Mul(u2)\n",
    "    )\n",
    "    return lx2\n",
    "\n",
    "@torch.no_grad()\n",
    "def opt_sequential(model, dataloader, dev):\n",
    "    print('Starting ...')\n",
    "    \n",
    "    model.cpu()\n",
    "    model.gradient_checkpointing_disable()\n",
    "    model.eval()\n",
    "    use_cache = model.config.use_cache\n",
    "    model.config.use_cache = False\n",
    "    layers = model.model.layers\n",
    "    \n",
    "\n",
    "    model.model.embed_tokens = model.model.embed_tokens.to(dev) \n",
    "    model.model.rotary_emb = model.model.rotary_emb.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (n_samples, model.seqlen, model.config.hidden_size), dtype=dtype, device=\"cpu\"\n",
    "    )\n",
    "    cache = {'i': 0, 'attention_mask': None}\n",
    "\n",
    "    class Catcher(nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "        def forward(self, inp, **kwargs):\n",
    "            inps[cache['i']] = inp\n",
    "            cache['i'] += 1\n",
    "            cache['attention_mask'] = kwargs['attention_mask']\n",
    "            cache['position_embeddings'] = kwargs['position_embeddings']\n",
    "            raise ValueError\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    for batch in dataloader:\n",
    "        try:\n",
    "            model(batch.unsqueeze(0).to(dev))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    comp_inps = inps.clone()\n",
    "    attention_mask = cache['attention_mask']\n",
    "    position_embeddings = cache['position_embeddings']\n",
    "\n",
    "    print('Ready.')\n",
    "\n",
    "    layers = model.model.layers\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i].to(dev)\n",
    "\n",
    "        subset = find_layers(layer)\n",
    "        for j in range(n_samples):\n",
    "            inps[j] = layer(inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "\n",
    "        imp = layer.mlp.down_proj.o_norm\n",
    "        \n",
    "        for name in [\n",
    "            \"self_attn.q_proj\",\n",
    "            \"self_attn.v_proj\",\n",
    "            \"self_attn.o_proj\",\n",
    "            \"self_attn.k_proj\",\n",
    "            \"mlp.up_proj\",\n",
    "            \"mlp.gate_proj\",\n",
    "            \"mlp.down_proj\",\n",
    "        ]:\n",
    "            #if \"gate_proj\" not in name:\n",
    "            #    continue\n",
    "            to_opt = {n: p for n, p in layer.named_parameters() if \"weight\" in n and \"layernorm\" not in n}\n",
    "            if len(to_opt) > 0 and ((\"q_proj\" in name and i >= 1) or \"k_proj\" in name):\n",
    "                \n",
    "                for n, p in to_opt.items():\n",
    "                    p.requires_grad = True\n",
    "                print(to_opt.keys())\n",
    "\n",
    "                #opt = torch.optim.Adam(to_opt.values(), lr=1e-5)\n",
    "                #opt = Lamb(to_opt.values(), lr=1e-3, weight_decay=1e-4)\n",
    "                #sch = torch.optim.lr_scheduler.LinearLR(opt, start_factor=1e-8, total_iters=16)\n",
    "                lr = 3e-5\n",
    "                opt = BF16FusedAdamW(to_opt.values(), lr, weight_decay=1e-4)\n",
    "                sch = torch.optim.lr_scheduler.OneCycleLR(opt, lr, total_steps=n_samples*4 // 8, cycle_momentum=False)\n",
    "                err_before = 0\n",
    "                for j in range(n_samples):\n",
    "                    cur_out = layer(comp_inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "                    err_before += ((cur_out.float() - inps[j].cuda().float()).square() * imp).mean().item()\n",
    "\n",
    "                print(\"err before\", err_before)\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    for ep in range(4):\n",
    "                        err_total = 0\n",
    "                        for j in range(n_samples):\n",
    "                            cur_out = layer(comp_inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "                            err = ((cur_out.float() - inps[j].cuda().float()).square() * imp).sum()\n",
    "                            err.backward()\n",
    "                            if j % 8 == 7:\n",
    "                                opt.step()\n",
    "                                sch.step()\n",
    "                                layer.zero_grad(set_to_none=True)\n",
    "                            err_total += err.item() / inps.shape[1] / inps.shape[2]\n",
    "                        print(ep, err_total)\n",
    "\n",
    "                err_after = 0\n",
    "                for j in range(n_samples):\n",
    "                    cur_out = layer(comp_inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "                    err_after += ((cur_out.float() - inps[j].cuda().float()).square() * imp).mean().item()\n",
    "                print(\"err after \", err_after)\n",
    "                        \n",
    "            #gpts[name].free()\n",
    "            \n",
    "            print(i, name)\n",
    "            print('Pruning ...')\n",
    "            lx = subset[name]\n",
    "            \n",
    "            s1 = time.time()\n",
    "            #W2 = go_admm(lx)\n",
    "            W2, Ac, Bb, mid, = factorize(lx)\n",
    "            W2 = W2.T\n",
    "            err_spxsp = (W2.T - lx.weight).square().sum().item()\n",
    "            print(\"err_spxsp\", err_spxsp)\n",
    "            \n",
    "            \n",
    "            lx.weight.data = W2.T.to(lx.weight)\n",
    "            lx.weight.A = Ac\n",
    "            lx.weight.B = Bb\n",
    "            lx.weight.mid = mid\n",
    "            parts = name.split('.')\n",
    "            block = getattr(layer, parts[0])\n",
    "            setattr(block, parts[1], replace(lx))\n",
    "            \n",
    "            \n",
    "            \n",
    "        for j in range(n_samples):\n",
    "            comp_inps[j] = layer(comp_inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "            \n",
    "        layers[i] = layer.cpu()\n",
    "        del layer\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "start = time.time()\n",
    "model.cpu()\n",
    "opt_sequential(model, dataloader, DEV)\n",
    "print(\"total time\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef7480f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:53:30.401542Z",
     "iopub.status.busy": "2023-12-26T11:53:30.401087Z",
     "iopub.status.idle": "2023-12-26T11:53:30.420226Z",
     "shell.execute_reply": "2023-12-26T11:53:30.419662Z"
    },
    "papermill": {
     "duration": 0.038429,
     "end_time": "2023-12-26T11:53:30.422134",
     "exception": false,
     "start_time": "2023-12-26T11:53:30.383705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def opt_eval(model, testenc, dev, dataset: str, log_wandb: bool = False):\n",
    "    print('Evaluating ...')\n",
    "\n",
    "    testenc = testenc.input_ids\n",
    "    nsamples = testenc.numel() // model.seqlen\n",
    "\n",
    "    use_cache = model.config.use_cache\n",
    "    model.config.use_cache = False\n",
    "    layers = model.model.layers\n",
    "\n",
    "    model.model.embed_tokens = model.model.embed_tokens.to(dev)\n",
    "    model.model.rotary_emb = model.model.rotary_emb.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (nsamples, model.seqlen, model.config.hidden_size), dtype=dtype, device=dev\n",
    "    )\n",
    "    cache = {'i': 0, 'attention_mask': None}\n",
    "\n",
    "    class Catcher(nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "        def forward(self, inp, **kwargs):\n",
    "            inps[cache['i']] = inp\n",
    "            cache['i'] += 1\n",
    "            cache['attention_mask'] = kwargs['attention_mask']\n",
    "            cache['position_embeddings'] = kwargs['position_embeddings']\n",
    "            raise ValueError\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    for i in range(nsamples):\n",
    "        batch = testenc[:, (i * model.seqlen):((i + 1) * model.seqlen)].to(dev)\n",
    "        try:\n",
    "            model(batch)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    outs = torch.zeros_like(inps)\n",
    "    attention_mask = cache['attention_mask']\n",
    "    position_embeddings = cache['position_embeddings']\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        print(i)\n",
    "        layer = layers[i].to(dev)\n",
    "\n",
    "        \n",
    "        for j in range(nsamples):\n",
    "            outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "        layers[i] = layer.cpu()\n",
    "        del layer\n",
    "        torch.cuda.empty_cache()\n",
    "        inps, outs = outs, inps\n",
    "\n",
    "    if model.model.norm is not None:\n",
    "        model.model.norm = model.model.norm.to(dev)\n",
    "    model.lm_head = model.lm_head.to(dev)\n",
    "\n",
    "    testenc = testenc.to(dev)\n",
    "    nlls = []\n",
    "    for i in range(nsamples):\n",
    "        hidden_states = inps[i].unsqueeze(0)\n",
    "        if model.model.norm is not None:\n",
    "            hidden_states = model.model.norm(hidden_states)\n",
    "        lm_logits = model.lm_head(hidden_states)\n",
    "        shift_logits = lm_logits[:, :-1, :].contiguous()\n",
    "        shift_labels = testenc[\n",
    "            :, (i * model.seqlen):((i + 1) * model.seqlen)\n",
    "        ][:, 1:]\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "        neg_log_likelihood = loss.float() * model.seqlen\n",
    "        nlls.append(neg_log_likelihood)\n",
    "    ppl = torch.exp(torch.stack(nlls).sum() / (nsamples * model.seqlen))\n",
    "    print(f\"Perplexity: {ppl.item():3f}\")\n",
    "    if log_wandb:\n",
    "         wandb.log({f'{dataset}/perplexity': ppl.item()})\n",
    "\n",
    "    model.config.use_cache = use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "448fd6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:53:30.497357Z",
     "iopub.status.busy": "2023-12-26T11:53:30.496880Z",
     "iopub.status.idle": "2023-12-26T11:56:24.045683Z",
     "shell.execute_reply": "2023-12-26T11:56:24.044885Z"
    },
    "papermill": {
     "duration": 173.580751,
     "end_time": "2023-12-26T11:56:24.048044",
     "exception": false,
     "start_time": "2023-12-26T11:53:30.467293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikitext2\n",
      "Evaluating ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Perplexity: 10.661325\n"
     ]
    }
   ],
   "source": [
    "model.gradient_checkpointing_disable()\n",
    "model.eval()\n",
    "\n",
    "for dataset in ['wikitext2']:\n",
    "    dataloader, testloader = get_loaders(\n",
    "        dataset, seed=0, model=model_name, seqlen=model.seqlen\n",
    "    )\n",
    "    print(dataset)\n",
    "    opt_eval(model, testloader, DEV, dataset, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1397c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/mnt/nvme/llamapush/llama2-7B-dsf1bit-15-ft.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e695e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1090.722145,
   "end_time": "2023-12-26T11:56:25.741463",
   "environment_variables": {},
   "exception": null,
   "input_path": "Llama prune-params-WU.ipynb",
   "output_path": "outputs/Llama-0.6-per_layer-admm-20-iterp15WU.ipynb",
   "parameters": {
    "iterative_prune": 15,
    "iters": 20,
    "sparsity": 0.6
   },
   "start_time": "2023-12-26T11:38:15.019318",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06d87db571ab4d88b82f52214601bb42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7ceac1ff43d4e279a2e938bbe2a9758",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b25d62f1cc0c4f73986ede9999476992",
       "tabbable": null,
       "tooltip": null,
       "value": 33
      }
     },
     "10900902714f449e933af1fbb5b4c688": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d15d5f8d6c74e0a8b2a6a56df56d8f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "62690d5acae24b38b50cb74283306762": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9c30a1d8ffe74cfdb177e547c15b771d",
       "placeholder": "​",
       "style": "IPY_MODEL_b64151aeaf904f719d868882ef9e600f",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "84e75e03350d40dd8bf62fdd06a61df7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_62690d5acae24b38b50cb74283306762",
        "IPY_MODEL_06d87db571ab4d88b82f52214601bb42",
        "IPY_MODEL_e6f6ce88afbc4f6199222b97e1218d81"
       ],
       "layout": "IPY_MODEL_c4d01b52ee784af28749c6928e95c0dd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9c30a1d8ffe74cfdb177e547c15b771d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b25d62f1cc0c4f73986ede9999476992": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b64151aeaf904f719d868882ef9e600f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b7ceac1ff43d4e279a2e938bbe2a9758": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4d01b52ee784af28749c6928e95c0dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6f6ce88afbc4f6199222b97e1218d81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10900902714f449e933af1fbb5b4c688",
       "placeholder": "​",
       "style": "IPY_MODEL_4d15d5f8d6c74e0a8b2a6a56df56d8f2",
       "tabbable": null,
       "tooltip": null,
       "value": " 33/33 [00:18&lt;00:00,  1.72it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
