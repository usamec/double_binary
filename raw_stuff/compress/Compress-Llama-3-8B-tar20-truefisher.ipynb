{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1a8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35287ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:38:17.209421Z",
     "iopub.status.busy": "2023-12-26T11:38:17.208962Z",
     "iopub.status.idle": "2023-12-26T11:38:20.906875Z",
     "shell.execute_reply": "2023-12-26T11:38:20.905911Z"
    },
    "papermill": {
     "duration": 3.727175,
     "end_time": "2023-12-26T11:38:20.909562",
     "exception": false,
     "start_time": "2023-12-26T11:38:17.182387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from quant_gpt import *\n",
    "#from sparsegpt import *\n",
    "from modelutils import *\n",
    "from datautils import *\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from bf16_fused_adam import BF16FusedAdamW\n",
    "import datasets\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf0db9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:38:20.927014Z",
     "iopub.status.busy": "2023-12-26T11:38:20.926394Z",
     "iopub.status.idle": "2023-12-26T11:38:20.933689Z",
     "shell.execute_reply": "2023-12-26T11:38:20.932806Z"
    },
    "papermill": {
     "duration": 0.017022,
     "end_time": "2023-12-26T11:38:20.935379",
     "exception": false,
     "start_time": "2023-12-26T11:38:20.918357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_opt(model):\n",
    "    import torch\n",
    "    def skip(*args, **kwargs):\n",
    "        pass\n",
    "    torch.nn.init.kaiming_uniform_ = skip\n",
    "    torch.nn.init.uniform_ = skip\n",
    "    torch.nn.init.normal_ = skip\n",
    "    from transformers import AutoModelForCausalLM\n",
    "    model = AutoModelForCausalLM.from_pretrained(model, torch_dtype='auto', cache_dir=\"/mnt/nvme/llm_weights\")\n",
    "    print(\"ms\", model.config.max_position_embeddings)\n",
    "    model.seqlen = 1024*8# model.config.max_position_embeddings\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d09b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:38:20.949258Z",
     "iopub.status.busy": "2023-12-26T11:38:20.948788Z",
     "iopub.status.idle": "2023-12-26T11:38:40.523396Z",
     "shell.execute_reply": "2023-12-26T11:38:40.522532Z"
    },
    "papermill": {
     "duration": 19.585753,
     "end_time": "2023-12-26T11:38:40.527104",
     "exception": false,
     "start_time": "2023-12-26T11:38:20.941351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe4c8517ed04ccdbdab4135f0b879fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms 8192\n",
      "8030261248 6979584000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "model = get_opt(model_name)\n",
    "model.eval()\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.model.layers.parameters()))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf2732ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:38:40.545044Z",
     "iopub.status.busy": "2023-12-26T11:38:40.544530Z",
     "iopub.status.idle": "2023-12-26T11:39:00.491876Z",
     "shell.execute_reply": "2023-12-26T11:39:00.491195Z"
    },
    "papermill": {
     "duration": 19.957607,
     "end_time": "2023-12-26T11:39:00.494561",
     "exception": false,
     "start_time": "2023-12-26T11:38:40.536954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 8192])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 256\n",
    "\n",
    "ds = datasets.load_from_disk(\"/home/usamec/magic_train/AQLM/redpajama_tokenized_llama3/\")\n",
    "\n",
    "np.random.seed(47)\n",
    "inds = np.random.randint(0, len(ds), size=n_samples)\n",
    "\n",
    "dataloader = torch.LongTensor(ds[inds][\"input_ids\"])\n",
    "dataloader.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b0c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "model.layers.0.input_layernorm.weight\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "model.layers.1.mlp.gate_proj.weight\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "model.layers.1.input_layernorm.weight\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "model.layers.2.input_layernorm.weight\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "model.layers.3.input_layernorm.weight\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "model.layers.4.input_layernorm.weight\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "model.layers.5.input_layernorm.weight\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "model.layers.6.input_layernorm.weight\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "model.layers.7.input_layernorm.weight\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "model.layers.8.input_layernorm.weight\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "model.layers.9.input_layernorm.weight\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "model.layers.10.input_layernorm.weight\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "model.layers.11.input_layernorm.weight\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "model.layers.12.input_layernorm.weight\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "model.layers.13.input_layernorm.weight\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "model.layers.14.input_layernorm.weight\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "model.layers.15.input_layernorm.weight\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "model.layers.16.input_layernorm.weight\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "model.layers.17.input_layernorm.weight\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "model.layers.19.input_layernorm.weight\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "model.layers.20.input_layernorm.weight\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "model.layers.21.input_layernorm.weight\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "model.layers.22.input_layernorm.weight\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "model.layers.23.input_layernorm.weight\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "model.layers.24.input_layernorm.weight\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "model.layers.25.input_layernorm.weight\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "model.layers.26.input_layernorm.weight\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "model.layers.27.input_layernorm.weight\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "model.layers.28.input_layernorm.weight\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "model.layers.29.input_layernorm.weight\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "model.layers.30.input_layernorm.weight\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "model.layers.31.input_layernorm.weight\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "model.norm.weight\n",
      "lm_head.weight\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.28.self_attn.q_proj\n",
      "model.layers.28.self_attn.k_proj\n",
      "model.layers.28.self_attn.v_proj\n",
      "model.layers.28.self_attn.o_proj\n",
      "model.layers.28.mlp.gate_proj\n",
      "model.layers.28.mlp.up_proj\n",
      "model.layers.28.mlp.down_proj\n",
      "model.layers.29.self_attn.q_proj\n",
      "model.layers.29.self_attn.k_proj\n",
      "model.layers.29.self_attn.v_proj\n",
      "model.layers.29.self_attn.o_proj\n",
      "model.layers.29.mlp.gate_proj\n",
      "model.layers.29.mlp.up_proj\n",
      "model.layers.29.mlp.down_proj\n",
      "model.layers.30.self_attn.q_proj\n",
      "model.layers.30.self_attn.k_proj\n",
      "model.layers.30.self_attn.v_proj\n",
      "model.layers.30.self_attn.o_proj\n",
      "model.layers.30.mlp.gate_proj\n",
      "model.layers.30.mlp.up_proj\n",
      "model.layers.30.mlp.down_proj\n",
      "model.layers.31.self_attn.q_proj\n",
      "model.layers.31.self_attn.k_proj\n",
      "model.layers.31.self_attn.v_proj\n",
      "model.layers.31.self_attn.o_proj\n",
      "model.layers.31.mlp.gate_proj\n",
      "model.layers.31.mlp.up_proj\n",
      "model.layers.31.mlp.down_proj\n",
      "torch.Size([8192])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8192])\n",
      "tensor(2.3494, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "0 tensor(2.3494, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4807, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "1 tensor(2.4807, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8724, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "2 tensor(2.8724, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2445, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "3 tensor(3.2445, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5263, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "4 tensor(2.5263, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2913, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "5 tensor(2.2913, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.8055, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "6 tensor(0.8055, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.6617, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "7 tensor(0.6617, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.1562, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "8 tensor(3.1562, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1847, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "9 tensor(2.1847, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1610, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "10 tensor(2.1610, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.5621, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "11 tensor(0.5621, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8135, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "12 tensor(2.8135, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.9604, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "13 tensor(2.9604, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4634, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "14 tensor(2.4634, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0964, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "15 tensor(2.0964, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.1119, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "16 tensor(3.1119, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2314, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "17 tensor(3.2314, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5751, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "18 tensor(2.5751, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9837, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "19 tensor(1.9837, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3780, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "20 tensor(2.3780, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.9995, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "21 tensor(2.9995, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3654, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "22 tensor(2.3654, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.8162, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "23 tensor(1.8162, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7335, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "24 tensor(2.7335, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2014, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "25 tensor(2.2014, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7080, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "26 tensor(2.7080, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5844, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "27 tensor(2.5844, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9835, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "28 tensor(1.9835, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7944, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "29 tensor(2.7944, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3560, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "30 tensor(2.3560, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.1546, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "31 tensor(1.1546, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.1339, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "32 tensor(3.1339, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7207, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "33 tensor(2.7207, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4257, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "34 tensor(2.4257, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5268, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "35 tensor(2.5268, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6874, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "36 tensor(2.6874, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.6238, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "37 tensor(1.6238, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1179, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "38 tensor(2.1179, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3830, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "39 tensor(2.3830, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0277, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "40 tensor(3.0277, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0862, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "41 tensor(2.0862, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.4091, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "42 tensor(1.4091, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.4389, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "43 tensor(1.4389, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5899, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "44 tensor(2.5899, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3375, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "45 tensor(2.3375, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6597, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "46 tensor(2.6597, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4744, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "47 tensor(2.4744, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1940, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "48 tensor(2.1940, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6711, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "49 tensor(2.6711, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5632, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "50 tensor(2.5632, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.3340, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "51 tensor(3.3340, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2987, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "52 tensor(3.2987, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2370, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "53 tensor(2.2370, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6549, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "54 tensor(2.6549, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2237, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "55 tensor(3.2237, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7525, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "56 tensor(2.7525, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3362, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "57 tensor(2.3362, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3183, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "58 tensor(2.3183, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0422, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "59 tensor(2.0422, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.7621, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "60 tensor(0.7621, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.9202, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "61 tensor(0.9202, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.9981, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "62 tensor(2.9981, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3589, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "63 tensor(2.3589, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0952, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "64 tensor(2.0952, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.1282, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "65 tensor(3.1282, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9576, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "66 tensor(1.9576, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8147, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "67 tensor(2.8147, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.3840, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "68 tensor(3.3840, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.1663, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "69 tensor(1.1663, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1121, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "70 tensor(2.1121, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5231, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "71 tensor(2.5231, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5279, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "72 tensor(2.5279, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4710, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "73 tensor(2.4710, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8104, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "74 tensor(2.8104, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0375, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "75 tensor(2.0375, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4741, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "76 tensor(2.4741, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3961, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "77 tensor(2.3961, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5286, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "78 tensor(2.5286, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6081, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "79 tensor(2.6081, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1867, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "80 tensor(2.1867, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5361, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "81 tensor(2.5361, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0719, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "82 tensor(2.0719, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2167, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "83 tensor(2.2167, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.9896, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "84 tensor(2.9896, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7712, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "85 tensor(2.7712, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6745, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "86 tensor(2.6745, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6829, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "87 tensor(2.6829, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.7234, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "88 tensor(1.7234, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6760, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "89 tensor(2.6760, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2407, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "90 tensor(2.2407, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5419, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "91 tensor(2.5419, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5130, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "92 tensor(2.5130, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3563, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "93 tensor(2.3563, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1965, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "94 tensor(2.1965, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2053, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "95 tensor(2.2053, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.3868, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "96 tensor(3.3868, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7424, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "97 tensor(2.7424, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0735, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "98 tensor(3.0735, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3654, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "99 tensor(2.3654, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4664, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "100 tensor(2.4664, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8688, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "101 tensor(2.8688, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1433, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "102 tensor(2.1433, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.9764, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "103 tensor(2.9764, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4629, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "104 tensor(2.4629, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7733, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "105 tensor(2.7733, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3996, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "106 tensor(2.3996, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7039, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "107 tensor(2.7039, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4697, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "108 tensor(2.4697, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5219, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "109 tensor(2.5219, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2584, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "110 tensor(2.2584, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4875, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "111 tensor(2.4875, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4694, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "112 tensor(2.4694, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.5194, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "113 tensor(0.5194, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.1010, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "114 tensor(3.1010, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9126, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "115 tensor(1.9126, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7173, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "116 tensor(2.7173, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4183, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "117 tensor(2.4183, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.3548, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "118 tensor(1.3548, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "119 tensor(1.1325, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5514, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "120 tensor(2.5514, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3647, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "121 tensor(2.3647, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8537, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "122 tensor(2.8537, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8192])\n",
      "tensor(2.5111, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "123 tensor(2.5111, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4168, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "124 tensor(2.4168, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7836, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "125 tensor(2.7836, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9914, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "126 tensor(1.9914, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.0704, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "127 tensor(1.0704, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.7087, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "128 tensor(0.7087, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.4503, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "129 tensor(3.4503, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.8171, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "130 tensor(1.8171, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2027, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "131 tensor(2.2027, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7616, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "132 tensor(2.7616, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.8657, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "133 tensor(1.8657, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.5197, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "134 tensor(3.5197, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.1032, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "135 tensor(3.1032, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7288, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "136 tensor(2.7288, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7695, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "137 tensor(2.7695, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0638, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "138 tensor(3.0638, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4343, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "139 tensor(2.4343, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0261, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "140 tensor(2.0261, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2652, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "141 tensor(2.2652, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6073, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "142 tensor(2.6073, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6730, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "143 tensor(2.6730, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3878, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "144 tensor(2.3878, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.5262, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "145 tensor(1.5262, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.8052, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "146 tensor(1.8052, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.6617, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "147 tensor(1.6617, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1848, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "148 tensor(2.1848, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.2237, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "149 tensor(1.2237, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6961, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "150 tensor(2.6961, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.5527, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "151 tensor(0.5527, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4824, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "152 tensor(2.4824, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9372, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "153 tensor(1.9372, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.5453, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "154 tensor(1.5453, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7547, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "155 tensor(2.7547, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.6342, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "156 tensor(1.6342, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.5667, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "157 tensor(1.5667, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9823, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "158 tensor(1.9823, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2334, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "159 tensor(2.2334, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6884, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "160 tensor(2.6884, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8814, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "161 tensor(2.8814, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4858, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "162 tensor(2.4858, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7466, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "163 tensor(2.7466, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9906, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "164 tensor(1.9906, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7438, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "165 tensor(2.7438, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8575, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "166 tensor(2.8575, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5782, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "167 tensor(2.5782, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.3911, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "168 tensor(3.3911, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.8541, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "169 tensor(0.8541, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.4186, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "170 tensor(1.4186, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.6852, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "171 tensor(1.6852, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3549, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "172 tensor(2.3549, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7027, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "173 tensor(2.7027, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0322, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "174 tensor(3.0322, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7583, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "175 tensor(2.7583, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5024, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "176 tensor(2.5024, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6765, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "177 tensor(2.6765, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.0920, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "178 tensor(1.0920, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6176, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "179 tensor(2.6176, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.9174, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "180 tensor(0.9174, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0932, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "181 tensor(3.0932, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.4898, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "182 tensor(3.4898, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8399, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "183 tensor(2.8399, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5163, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "184 tensor(2.5163, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0304, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "185 tensor(2.0304, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0665, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "186 tensor(2.0665, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5657, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "187 tensor(2.5657, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.2563, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "188 tensor(1.2563, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6529, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "189 tensor(2.6529, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6389, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "190 tensor(2.6389, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3662, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "191 tensor(2.3662, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1316, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "192 tensor(2.1316, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7007, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "193 tensor(2.7007, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9523, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "194 tensor(1.9523, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2678, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "195 tensor(2.2678, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0465, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "196 tensor(3.0465, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.1518, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "197 tensor(1.1518, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.9376, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "198 tensor(2.9376, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4388, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "199 tensor(2.4388, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.9427, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "200 tensor(2.9427, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6487, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "201 tensor(2.6487, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8441, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "202 tensor(2.8441, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.8670, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "203 tensor(1.8670, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3008, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "204 tensor(2.3008, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.1965, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "205 tensor(3.1965, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.4721, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "206 tensor(3.4721, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2670, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "207 tensor(2.2670, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0776, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "208 tensor(3.0776, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6001, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "209 tensor(2.6001, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.9948, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "210 tensor(1.9948, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4427, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "211 tensor(2.4427, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.1915, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "212 tensor(1.1915, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7530, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "213 tensor(2.7530, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.8049, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "214 tensor(1.8049, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2571, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "215 tensor(3.2571, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2243, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "216 tensor(2.2243, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0126, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "217 tensor(3.0126, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8435, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "218 tensor(2.8435, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.4221, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "219 tensor(3.4221, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5728, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "220 tensor(2.5728, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.6479, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "221 tensor(3.6479, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2864, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "222 tensor(3.2864, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.0338, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "223 tensor(3.0338, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1683, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "224 tensor(2.1683, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.8240, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "225 tensor(0.8240, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.7311, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "226 tensor(1.7311, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2865, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "227 tensor(3.2865, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2279, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "228 tensor(2.2279, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0986, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "229 tensor(2.0986, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.4518, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "230 tensor(3.4518, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5277, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "231 tensor(2.5277, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5367, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "232 tensor(2.5367, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8598, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "233 tensor(2.8598, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.7949, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "234 tensor(1.7949, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.4394, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "235 tensor(2.4394, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1499, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "236 tensor(2.1499, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6952, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "237 tensor(2.6952, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0175, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "238 tensor(2.0175, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3632, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "239 tensor(2.3632, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.8184, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "240 tensor(2.8184, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "241 tensor(1.6094, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.5455, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "242 tensor(0.5455, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7955, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "243 tensor(2.7955, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6980, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "244 tensor(2.6980, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3627, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "245 tensor(2.3627, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2623, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "246 tensor(3.2623, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.2037, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "247 tensor(2.2037, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.7099, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "248 tensor(2.7099, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.5804, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "249 tensor(2.5804, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(3.2242, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "250 tensor(3.2242, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(0.8355, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "251 tensor(0.8355, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.3746, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "252 tensor(2.3746, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.6777, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "253 tensor(2.6777, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.1549, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "254 tensor(2.1549, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "torch.Size([8192])\n",
      "torch.Size([1, 8192])\n",
      "tensor(2.0993, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n",
      "255 tensor(2.0993, device='cuda:0', grad_fn=<LinearCrossEntropyFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "from cut_cross_entropy import linear_cross_entropy\n",
    "\n",
    "model.cuda()\n",
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False\n",
    "model.train()\n",
    "\n",
    "def f_hook(m, i, o):\n",
    "    X = i[0].detach().float()\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    m.i_norm += X.square().mean(dim=0)\n",
    "    \n",
    "def b_hook(m, _, go):\n",
    "    X = go[0].detach().float()\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    m.o_norm += X.square().mean(dim=0) * 1e6\n",
    "\n",
    "for n, p in model.named_parameters():\n",
    "    print(n)\n",
    "    if \"embed_tokens\" not in n:\n",
    "        p.requires_grad = False\n",
    "\n",
    "handles = []\n",
    "\n",
    "for n, m in model.named_modules():\n",
    "    if type(m) == nn.Linear and \"lm_head\" not in n:\n",
    "        print(n)\n",
    "        m.i_norm = torch.zeros(m.weight.shape[1], device=m.weight.device)\n",
    "        m.o_norm = torch.zeros(m.weight.shape[0], device=m.weight.device)\n",
    "        handles.append(m.register_forward_hook(f_hook))\n",
    "        handles.append(m.register_full_backward_hook(b_hook))\n",
    "\n",
    "for idx, bx in enumerate(dataloader):\n",
    "    #print(bx)\n",
    "    print(bx.shape)\n",
    "    bx = bx.cuda().unsqueeze(0)\n",
    "    #lm_logits = model(bx.cuda()).logits\n",
    "    embs = model.model(bx.cuda())[0]\n",
    "    with torch.no_grad():\n",
    "        step = 1024\n",
    "        labels = []\n",
    "        for i in range(0, embs.shape[1], step):\n",
    "            out = torch.softmax(model.lm_head(embs[:,i:i+step]), dim=-1)\n",
    "            labels.append(torch.multinomial(out[0], 1).reshape(1, -1))\n",
    "        labels = torch.cat(labels, dim=1)\n",
    "        print(labels.shape)\n",
    "        del out\n",
    "    loss = linear_cross_entropy(embs, model.lm_head.weight, labels)\n",
    "    print(loss)\n",
    "    #print(loss2)\n",
    "    #qq = qqqq\n",
    "    print(idx, loss)\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    \n",
    "for h in handles:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813e9daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1308,  2.0571,  0.3403])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 5)\n",
    "a.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8596d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration(A, num_iters=5):\n",
    "    \"\"\"\n",
    "    Performs power iteration to compute the top singular vectors and value.\n",
    "    \n",
    "    Arguments:\n",
    "        A (torch.Tensor): The input matrix of shape (m, n).\n",
    "        num_iters (int): Number of iterations to perform.\n",
    "    \n",
    "    Returns:\n",
    "        u (torch.Tensor): Dominant left singular vector (m,).\n",
    "        sigma (torch.Tensor): Dominant singular value (scalar).\n",
    "        v (torch.Tensor): Dominant right singular vector (n,).\n",
    "    \"\"\"\n",
    "    # Start with a random vector on the appropriate device\n",
    "    n = A.shape[1]\n",
    "    v = torch.randn(n, device=A.device)\n",
    "    v = v / torch.norm(v)\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "        # Multiply A*v\n",
    "        u = torch.mv(A, v)\n",
    "        u_norm = torch.norm(u)\n",
    "        if u_norm == 0:\n",
    "            break\n",
    "        u = u / u_norm\n",
    "        \n",
    "        # Multiply A^T*u\n",
    "        v = torch.mv(A.t(), u)\n",
    "        v_norm = torch.norm(v)\n",
    "        if v_norm == 0:\n",
    "            break\n",
    "        v = v / v_norm\n",
    "    \n",
    "    # Estimate the dominant singular value as ||A*v||\n",
    "    sigma = torch.norm(torch.mv(A, v))\n",
    "    # The left singular vector corresponding to sigma:\n",
    "    u = torch.mv(A, v) / sigma\n",
    "    return u, sigma, v\n",
    "\n",
    "def svd_abs(W):\n",
    "    Sg = W.sign()\n",
    "    Sg[Sg == 0] = 1\n",
    "    u, s, v = power_iteration(W.abs(), num_iters=5)\n",
    "    apx = s * torch.ger(u, v)\n",
    "    \n",
    "    return apx * Sg\n",
    "\n",
    "def find_other2(A, W, nnz, Z, U, print_sc=None, debug=False, reg=0, rho_start=0.03, iters=3, prune_iters=1, flip=False, final=False):\n",
    "    XX = A.T.matmul(A)\n",
    "    XX += torch.diag(torch.ones_like(XX.diag())) * XX.diag().mean() * reg\n",
    "    \n",
    "    #norm2 = torch.ones_like(norm2)\n",
    "    Wnn = W# * norm2.unsqueeze(1)\n",
    "    rho = 1\n",
    "    XY = A.T.matmul(Wnn)\n",
    "    XXinv = torch.inverse(XX + torch.eye(XX.shape[1], device=XX.device)*rho)\n",
    "    XXinv2 = torch.inverse(XX + torch.eye(XX.shape[1], device=XX.device)*rho_start)\n",
    "    U = U\n",
    "    Z = Z\n",
    "    \n",
    "    B = XXinv2.matmul(XY + rho_start*(Z-U))\n",
    "    \n",
    "    r_scale = c_scale = mask = None\n",
    "\n",
    "    for itt in range(iters-1):\n",
    "        Z = svd_abs(B+U)\n",
    "        #print(\"   \", \"z\", itt, (A.matmul(Z) - W).square().sum().item(), W.square().sum().item())\n",
    "\n",
    "        U = U + (B - Z)    \n",
    "\n",
    "        B = XXinv.matmul(XY + rho*(Z-U))\n",
    "\n",
    "    Z = svd_abs(B+U)\n",
    "    #print(\"   \", \"z\", iters-1, (A.matmul(Z) - W).square().sum().item(), W.square().sum().item())\n",
    "    U = U + (B - Z)\n",
    "   \n",
    "    return (Z), U\n",
    "\n",
    "\n",
    "def factorizeT(W, XX, o_norm, asp=0.16, sp=0.16, iters=80):\n",
    "    nza = int(W.shape[0]**2 * asp)\n",
    "    nzb = int(W.numel() * sp - nza)\n",
    "    \n",
    "    norm = XX.sqrt().unsqueeze(1) + 1e-8\n",
    "    norm_o = o_norm.sqrt() + 1e-8\n",
    "       \n",
    "    Wn = W * norm * norm_o\n",
    "       \n",
    "    mid = int(2*(W.shape[0]*W.shape[1]) / (W.shape[0] + W.shape[1]))\n",
    "    \n",
    "    Az = torch.randn((W.shape[0], mid), device=W.device)\n",
    "    Au = torch.zeros_like(Az)\n",
    "\n",
    "    Bz = torch.randn((mid, W.shape[1]), device=W.device)\n",
    "    Bu = torch.zeros_like(Bz)\n",
    "    \n",
    "    for itt in range(iters):\n",
    "        #if itt < 10:\n",
    "        #    rho_start = 0.0\n",
    "        #elif itt < 15:\n",
    "        #    rho_start = 0.00\n",
    "        #else:\n",
    "        #    rho_start = 0.1\n",
    "        rho_start = min(1.0, itt / (iters-3))**3\n",
    "        if True or itt > iters // 2:\n",
    "            nzaa = nza\n",
    "            nzbb = nzb\n",
    "        else:\n",
    "            alph = (itt / (iters // 2))**2\n",
    "            nzaa = int(nza / 2 * (1-alph) + nza * alph)\n",
    "            nzbb = int(nzb / 2 * (1-alph) + nzb * alph)\n",
    "\n",
    "            \n",
    "        mid = Bz.norm(dim=1) + 1e-12\n",
    "        final = itt == iters - 1\n",
    "        \n",
    "        Az, Au = (x.T for x in find_other2(Bz.T / mid, Wn.T, nzaa, Az.T, Au.T, reg=3e-2, debug=False, rho_start=rho_start, flip=True, final=final))\n",
    "        mid = Az.norm(dim=0) + 1e-12\n",
    "        Bz, Bu = find_other2(Az / mid, Wn, nzbb, Bz, Bu, reg=3e-2, debug=False, rho_start=rho_start, final=final)\n",
    "        #print(\"err\", itt, ((Az / mid).matmul(Bz) - Wn).square().sum().item(), (Wn).square().sum().item())\n",
    "        if itt == iters - 1:\n",
    "            print(\"err\", itt, ((Az / mid).matmul(Bz) - Wn).square().sum().item(), (Wn).square().sum().item())\n",
    "            \n",
    "    return ((Az / norm).matmul(Bz / norm_o)).T, (Bz / norm_o).T, (Az / norm).T, 1 / mid\n",
    "\n",
    "\n",
    "def factorizef(W, XX, o_norm, asp=0.16, sp=0.16, iters=80, l_prev=None):\n",
    "    s_time = time.time()\n",
    "    if W.shape[0] >= W.shape[1]:\n",
    "        return factorizeT(W.T, XX, o_norm, asp, sp=sp, iters=iters)\n",
    "    \n",
    "    #print(\"a\")\n",
    "    nza = int(W.shape[0]**2 * asp)\n",
    "    nzb = int(W.numel() * sp - nza)\n",
    "    norm = XX.sqrt() + 1e-8\n",
    "    norm_o = (o_norm.sqrt() + 1e-8).unsqueeze(1)\n",
    "\n",
    "    Wn = W * norm * norm_o\n",
    "    mid = int(2*(W.shape[0]*W.shape[1]) / (W.shape[0] + W.shape[1]))\n",
    "    \n",
    "    Az = torch.randn((W.shape[0], mid), device=W.device)\n",
    "    Au = torch.zeros_like(Az)\n",
    "\n",
    "    Bz = torch.randn((mid, W.shape[1]), device=W.device)\n",
    "    Bu = torch.zeros_like(Bz)\n",
    "    \n",
    "    for itt in range(iters):\n",
    "        #if itt < 10:\n",
    "        #    rho_start = 0.0\n",
    "        #elif itt < 15:\n",
    "        #    rho_start = 0.00\n",
    "        #else:\n",
    "        #    rho_start = 0.1\n",
    "            \n",
    "        rho_start = min(1.0, itt / (iters-3))**3\n",
    "        if True or itt > iters // 2:\n",
    "            nzaa = nza\n",
    "            nzbb = nzb\n",
    "        else:\n",
    "            alph = (itt / (iters // 2))**2\n",
    "            nzaa = int(nza / 2 * (1-alph) + nza * alph)\n",
    "            nzbb = int(nzb / 2 * (1-alph) + nzb * alph)\n",
    "            \n",
    "        \n",
    "        final = itt == iters - 1\n",
    "        mid = Bz.norm(dim=1) + 1e-12\n",
    "        Az, Au = (x.T for x in find_other2(Bz.T / mid, Wn.T, nzaa, Az.T, Au.T, reg=3e-2, debug=False, rho_start=rho_start, final=final))        \n",
    "        mid = Az.norm(dim=0) + 1e-12\n",
    "        Bz, Bu = find_other2(Az / mid, Wn, nzbb, Bz, Bu, reg=3e-2, debug=False, rho_start=rho_start, flip=True, final=final)\n",
    "        #print(\"err\", itt, ((Az / mid).matmul(Bz) - Wn).square().sum().item(), (Wn).square().sum().item())\n",
    "        #print(itt, time.time() - s_time, end =\" \") \n",
    "        #print_scores(Az.matmul(Bz / norm))\n",
    "        if itt == iters - 1:\n",
    "            print(\"err\", itt, ((Az / mid).matmul(Bz) - Wn).square().sum().item(), (Wn).square().sum().item())\n",
    "            \n",
    "    return (Az / norm_o).matmul(Bz / norm), Az / norm_o, Bz / norm, 1 / mid\n",
    "\n",
    "def factorize(lx, l_prev=None):\n",
    "    W = lx.weight.detach().float()\n",
    "    \n",
    "    sm = min(W.shape)\n",
    "    lg = max(W.shape)\n",
    "    mid = sm\n",
    "    print(\"mid\", mid)\n",
    "    lim = 1.25\n",
    "    for density in np.linspace(0.1, 0.4, 301):\n",
    "        total_size = 0\n",
    "        total_pars = 0\n",
    "        total_pars += sm*lg\n",
    "        mask_size = sm*mid + mid*lg\n",
    "        total_ones2 = sm*lg * density\n",
    "        p=total_ones2 / mask_size\n",
    "        ent = -p*np.log2(p)-(1-p)*np.log2(1-p)\n",
    "        total_size += (total_ones2*2 + mask_size*ent)\n",
    "        #print(\" \", density, total_size / total_pars)\n",
    "        if total_size / total_pars < lim:\n",
    "            sp = density\n",
    "    \n",
    "    \n",
    "    if W.shape[0] == W.shape[1]:\n",
    "        asp = sp/2\n",
    "    else:\n",
    "        asp = sp\n",
    "    W2, Ab, Bb, mid = factorizef(W, lx.i_norm, lx.o_norm, asp=asp, sp=sp, l_prev=l_prev, iters=260)\n",
    "    Ac = Ab\n",
    "    \n",
    "    #Ac = Ab\n",
    "    #W3 = Ac.matmul(Bb)\n",
    "    \n",
    "    #Bc = get_at(lx.XX, W.T, Bb.T, Ac.T).T\n",
    "    Bc = Bb\n",
    "    \n",
    "    An = Ac.norm() + 1e-12\n",
    "    Bn = Bc.norm() + 1e-12\n",
    "    Ac *= (Bn/An).sqrt()\n",
    "    Bc *= (An/Bn).sqrt()\n",
    "    \n",
    "    W3 = (Ac * mid).matmul(Bc)\n",
    "    assert W3.shape == lx.weight.shape\n",
    "    print(\"sparsity check\", ((Ac != 0).sum() + (Bb != 0).sum()).item() / W3.numel())\n",
    "    return W3, Ac, Bc, mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18157288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...\n",
      "Ready.\n",
      "0 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.02251136302947998 65.54188537597656\n",
      "sparsity check 2.0\n",
      "err_spxsp 468.68701171875\n",
      "0 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 2.2661585807800293 91.12406158447266\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 34.14214324951172\n",
      "0 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.217251777648926 93.85585021972656\n",
      "sparsity check 2.0\n",
      "err_spxsp 130.71493530273438\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.0007081167309479497\n",
      "0 0.0005749390290930023\n",
      "1 0.0003986558707538279\n",
      "2 0.00030943803216132437\n",
      "3 0.00033691922641310157\n",
      "4 0.00037450268484917615\n",
      "5 0.0002733346295258343\n",
      "6 0.00024354968894613194\n",
      "7 0.00024091313537155656\n",
      "err after  0.00024067002590300035\n",
      "0 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.044764019548892975 31.515213012695312\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 264.477294921875\n",
      "0 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.8991804122924805 93.85063171386719\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 675.7127075195312\n",
      "0 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.15631103515625 69.1654052734375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 728.635986328125\n",
      "0 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 16.389862060546875 252.88673400878906\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 681.8772583007812\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.006507009138658759\n",
      "0 0.005551745061893598\n",
      "1 0.0045020128764008405\n",
      "2 0.006042632346179744\n",
      "3 0.0047112579241002095\n",
      "4 0.003404161495382141\n",
      "5 0.0028896344283566577\n",
      "6 0.0026937403640658886\n",
      "7 0.0026085537042490614\n",
      "err after  0.002583106629572285\n",
      "1 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.08687183260917664 34.9153938293457\n",
      "sparsity check 2.0\n",
      "err_spxsp 843.6658325195312\n",
      "1 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 26.03261947631836 665.181884765625\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 32.26713562011719\n",
      "1 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.345673084259033 83.95646667480469\n",
      "sparsity check 2.0\n",
      "err_spxsp 142.66714477539062\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.003722948461472697\n",
      "0 0.0035028607526328415\n",
      "1 0.003240840653234045\n",
      "2 0.0030236593247536803\n",
      "3 0.0028733112358168\n",
      "4 0.0027813850347229163\n",
      "5 0.002713509612931375\n",
      "6 0.002668840896603797\n",
      "7 0.002655937798863306\n",
      "err after  0.002656658536125178\n",
      "1 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.2169678509235382 58.22880554199219\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 246.12039184570312\n",
      "1 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 10.018736839294434 118.66580963134766\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 681.1817016601562\n",
      "1 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.422283172607422 108.45005798339844\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 769.3530883789062\n",
      "1 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 13.153854370117188 26223.99609375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 759.875732421875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.005712174610380316\n",
      "0 0.004893338753390708\n",
      "1 0.00435548302357347\n",
      "2 0.004049990775456536\n",
      "3 0.003808936759014614\n",
      "4 0.003650560978712747\n",
      "5 0.0035350786774870357\n",
      "6 0.003480249849417305\n",
      "7 0.0034640544745343504\n",
      "err after  0.0034625811231308035\n",
      "2 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.6785458922386169 83.96253204345703\n",
      "sparsity check 2.0\n",
      "err_spxsp 642.1682739257812\n",
      "2 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 176.10720825195312 3579.43701171875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 18.20567512512207\n",
      "2 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.1668033599853516 63.513702392578125\n",
      "sparsity check 2.0\n",
      "err_spxsp 107.05062866210938\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.004086468704372237\n",
      "0 0.0039602644046681235\n",
      "1 0.0038049274517106824\n",
      "2 0.003672828656817728\n",
      "3 0.0035791173486359185\n",
      "4 0.00354053129467502\n",
      "5 0.0034763346511681448\n",
      "6 0.003441560691499035\n",
      "7 0.0034317926265430287\n",
      "err after  0.0034312002189835766\n",
      "2 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 1.0878740549087524 128.65060424804688\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 332.93695068359375\n",
      "2 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.84685230255127 114.97547149658203\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 672.6923828125\n",
      "2 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.77863883972168 103.10548400878906\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 832.8048706054688\n",
      "2 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 12.755462646484375 157.68829345703125\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 677.9127197265625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.006211349553268519\n",
      "0 0.00550481063692132\n",
      "1 0.004929693059239071\n",
      "2 0.004596803058120713\n",
      "3 0.004441187856173201\n",
      "4 0.004373382346784638\n",
      "5 0.0042192992332275026\n",
      "6 0.00413666293843562\n",
      "7 0.004116235504625365\n",
      "err after  0.004114384349122702\n",
      "3 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 1.0273935794830322 51.85962677001953\n",
      "sparsity check 2.0\n",
      "err_spxsp 628.7337036132812\n",
      "3 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 142.41033935546875 1835.0274658203125\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 27.574710845947266\n",
      "3 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.656512260437012 125.96217346191406\n",
      "sparsity check 2.0\n",
      "err_spxsp 158.37884521484375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.005459198309836211\n",
      "0 0.005178601273655659\n",
      "1 0.00484997154580924\n",
      "2 0.004643433954697684\n",
      "3 0.004523909764429845\n",
      "4 0.004449403992111911\n",
      "5 0.00440333755886968\n",
      "6 0.004366954201032058\n",
      "7 0.00435574433504371\n",
      "err after  0.004354675513241091\n",
      "3 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 1.0957564115524292 56.65926742553711\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 307.64715576171875\n",
      "3 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 10.224746704101562 115.16303253173828\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 659.885009765625\n",
      "3 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.655849456787109 95.34180450439453\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 935.2127685546875\n",
      "3 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.349185943603516 133.56521606445312\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 635.4982299804688\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.0064723335181042785\n",
      "0 0.005582280971793807\n",
      "1 0.00505779377908766\n",
      "2 0.004787093071172421\n",
      "3 0.004708965946520038\n",
      "4 0.004607268812833354\n",
      "5 0.004480275918467669\n",
      "6 0.004415347796566493\n",
      "7 0.0043983855275655515\n",
      "err after  0.004396730389089498\n",
      "4 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.7129883766174316 49.15575408935547\n",
      "sparsity check 2.0\n",
      "err_spxsp 629.8646240234375\n",
      "4 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 55.16556167602539 794.336669921875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 31.070558547973633\n",
      "4 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.992839336395264 111.10005950927734\n",
      "sparsity check 2.0\n",
      "err_spxsp 165.8014678955078\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.005478504238453752\n",
      "0 0.0052596529421862215\n",
      "1 0.005019064371481363\n",
      "2 0.004836657689338608\n",
      "3 0.004726823630335275\n",
      "4 0.004670408685342409\n",
      "5 0.004625006913556717\n",
      "6 0.004586293031934474\n",
      "7 0.004576051771437051\n",
      "err after  0.004574901710839185\n",
      "4 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.8334589004516602 56.289127349853516\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 304.6792297363281\n",
      "4 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 10.712169647216797 120.6337890625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 637.8076782226562\n",
      "4 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err 259 6.7560248374938965 87.84046936035156\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1063.717529296875\n",
      "4 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 12.175310134887695 132.5177001953125\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 600.65673828125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.0062763877904217225\n",
      "0 0.005577531754170195\n",
      "1 0.005100305434098118\n",
      "2 0.004825340622119256\n",
      "3 0.004705603573711414\n",
      "4 0.004607358660905447\n",
      "5 0.004512219667958561\n",
      "6 0.004459036146727158\n",
      "7 0.004444942411282682\n",
      "err after  0.004443543476554623\n",
      "5 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.7870597243309021 48.33690643310547\n",
      "sparsity check 2.0\n",
      "err_spxsp 563.5994262695312\n",
      "5 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 22.6424560546875 349.7737121582031\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 20.921358108520508\n",
      "5 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.691104888916016 81.98316955566406\n",
      "sparsity check 2.0\n",
      "err_spxsp 133.18060302734375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.005158881735042087\n",
      "0 0.005018582140110084\n",
      "1 0.004854244936723262\n",
      "2 0.0047225932830770034\n",
      "3 0.0046422591749433195\n",
      "4 0.004608832866324519\n",
      "5 0.0045580589312521624\n",
      "6 0.004523137667092669\n",
      "7 0.004514282093623478\n",
      "err after  0.004513403016972006\n",
      "5 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.9059529900550842 51.943931579589844\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 272.93359375\n",
      "5 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.537732124328613 108.44367980957031\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 633.1910400390625\n",
      "5 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.769674777984619 78.24614715576172\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1039.5985107421875\n",
      "5 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 10.49356746673584 120.52886962890625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 598.7422485351562\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.006354803294016165\n",
      "0 0.005732738009101013\n",
      "1 0.005308267842337955\n",
      "2 0.00506798406058806\n",
      "3 0.004926940662699053\n",
      "4 0.004846929106861353\n",
      "5 0.004762255859532161\n",
      "6 0.004710795536993828\n",
      "7 0.004696823304584541\n",
      "err after  0.004695462171184772\n",
      "6 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.6823534965515137 33.333621978759766\n",
      "sparsity check 2.0\n",
      "err_spxsp 620.804931640625\n",
      "6 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 15.414958000183105 194.02487182617188\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 25.27093505859375\n",
      "6 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.501506328582764 78.96672058105469\n",
      "sparsity check 2.0\n",
      "err_spxsp 142.71641540527344\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.005456382566990214\n",
      "0 0.005332605260264245\n",
      "1 0.005162659814232029\n",
      "2 0.005024779682571534\n",
      "3 0.004943192154314602\n",
      "4 0.004904902385533205\n",
      "5 0.004854949231230421\n",
      "6 0.0048242564143947675\n",
      "7 0.0048158227145904675\n",
      "err after  0.004814875810552621\n",
      "6 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.783149778842926 42.009765625\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 300.0364074707031\n",
      "6 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.402931213378906 96.9268569946289\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 631.6412963867188\n",
      "6 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.833016872406006 66.06149291992188\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1047.914794921875\n",
      "6 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.478768348693848 106.93104553222656\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 595.1973876953125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.00676433766966511\n",
      "0 0.0062073205881461035\n",
      "1 0.005807213492516894\n",
      "2 0.005577259584242711\n",
      "3 0.005436775027192198\n",
      "4 0.005368235481000738\n",
      "5 0.005290992030495545\n",
      "6 0.0052311013405415\n",
      "7 0.005215319157287013\n",
      "err after  0.005213800779529265\n",
      "7 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.8304826617240906 35.821956634521484\n",
      "sparsity check 2.0\n",
      "err_spxsp 512.4605712890625\n",
      "7 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 10.764228820800781 145.64230346679688\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 21.380014419555664\n",
      "7 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.837987899780273 88.09446716308594\n",
      "sparsity check 2.0\n",
      "err_spxsp 141.99667358398438\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.006017222594891791\n",
      "0 0.005881973536816076\n",
      "1 0.005701275360479485\n",
      "2 0.005557930930081056\n",
      "3 0.005468415332870791\n",
      "4 0.005414766963440343\n",
      "5 0.005378655218919448\n",
      "6 0.005350436632397759\n",
      "7 0.005341279819731426\n",
      "err after  0.00534030026938126\n",
      "7 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.7869796752929688 38.514801025390625\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 275.0377502441406\n",
      "7 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.201128959655762 83.76863098144531\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 646.112060546875\n",
      "7 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.206274509429932 59.13868713378906\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1009.8941650390625\n",
      "7 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.368282318115234 95.30604553222656\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 594.4781494140625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.007036695071292343\n",
      "0 0.006603388133953558\n",
      "1 0.006217972355443635\n",
      "2 0.005980063717288431\n",
      "3 0.005850901721714763\n",
      "4 0.005757939172326587\n",
      "5 0.005684397836375865\n",
      "6 0.005642398729833076\n",
      "7 0.005624757262921776\n",
      "err after  0.00562320469362021\n",
      "8 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.7524333596229553 38.47126770019531\n",
      "sparsity check 2.0\n",
      "err_spxsp 500.2411193847656\n",
      "8 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 7.318683624267578 108.82807159423828\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 24.232913970947266\n",
      "8 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.5323896408081055 92.33247375488281\n",
      "sparsity check 2.0\n",
      "err_spxsp 142.28662109375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.006343970871967031\n",
      "0 0.006246711081985268\n",
      "1 0.0060963211944908835\n",
      "2 0.005965390153505723\n",
      "3 0.005886182820177055\n",
      "4 0.005845904586749384\n",
      "5 0.005798969830721035\n",
      "6 0.005768792430899339\n",
      "7 0.005760432828537887\n",
      "err after  0.00575953032966936\n",
      "8 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.6385155916213989 42.65647888183594\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 258.7953796386719\n",
      "8 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.458327293395996 75.89470672607422\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 631.9892578125\n",
      "8 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.6134040355682373 50.30405044555664\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 988.8096313476562\n",
      "8 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.853703498840332 89.33428955078125\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 586.13720703125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.0075313893667043885\n",
      "0 0.007059929466777248\n",
      "1 0.006677374842183781\n",
      "2 0.006447167945225374\n",
      "3 0.006315525590252946\n",
      "4 0.006238602740268107\n",
      "5 0.00618729511188576\n",
      "6 0.006115988910096348\n",
      "7 0.00610002487883321\n",
      "err after  0.006098450468925876\n",
      "9 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.7274149656295776 47.16733932495117\n",
      "sparsity check 2.0\n",
      "err_spxsp 491.1748046875\n",
      "9 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 8.707728385925293 179.92559814453125\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 35.13344955444336\n",
      "9 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.093264579772949 93.78373718261719\n",
      "sparsity check 2.0\n",
      "err_spxsp 162.44151306152344\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err before 0.006955082884815056\n",
      "0 0.006836724734966992\n",
      "1 0.006654552180407336\n",
      "2 0.006503055803477764\n",
      "3 0.006407386765204137\n",
      "4 0.006348888626234839\n",
      "5 0.006311247319899849\n",
      "6 0.006285104909693473\n",
      "7 0.0062756526058365125\n",
      "err after  0.006274544924963266\n",
      "9 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.580848217010498 48.462486267089844\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 278.1700439453125\n",
      "9 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.409770965576172 76.54510498046875\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 637.5906982421875\n",
      "9 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.4849166870117188 50.54972839355469\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1009.592041015625\n",
      "9 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.009498596191406 92.28413391113281\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 590.3419189453125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.008113616746413754\n",
      "0 0.007680654682189925\n",
      "1 0.0072989052951015765\n",
      "2 0.0070546881506743375\n",
      "3 0.00692313100262254\n",
      "4 0.006833637431554962\n",
      "5 0.006762526758393506\n",
      "6 0.006712760228765546\n",
      "7 0.006696154867313453\n",
      "err after  0.006694432031508768\n",
      "10 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.6451296210289001 44.977264404296875\n",
      "sparsity check 2.0\n",
      "err_spxsp 529.399658203125\n",
      "10 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 7.4455389976501465 117.10530090332031\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 22.583023071289062\n",
      "10 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.185678482055664 85.07074737548828\n",
      "sparsity check 2.0\n",
      "err_spxsp 148.73233032226562\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.007422621660225559\n",
      "0 0.007320517772313906\n",
      "1 0.007169699922087602\n",
      "2 0.007038188317892491\n",
      "3 0.0069600937131326646\n",
      "4 0.006913109307788545\n",
      "5 0.006862497253678157\n",
      "6 0.006834135916506057\n",
      "7 0.006825363878306234\n",
      "err after  0.006824369513196871\n",
      "10 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.6166454553604126 47.485103607177734\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 264.5755310058594\n",
      "10 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.109572410583496 72.135986328125\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 649.6054077148438\n",
      "10 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.3559412956237793 46.696128845214844\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 948.9873657226562\n",
      "10 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.678949356079102 89.19403076171875\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 595.3077392578125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.00845024450609344\n",
      "0 0.008032510899283807\n",
      "1 0.007659473987587262\n",
      "2 0.0074363798048580065\n",
      "3 0.007316989771425142\n",
      "4 0.007227339037854108\n",
      "5 0.007160670873417985\n",
      "6 0.007115566339052748\n",
      "7 0.007098343177858624\n",
      "err after  0.007096578432538081\n",
      "11 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.863425612449646 51.248878479003906\n",
      "sparsity check 2.0\n",
      "err_spxsp 481.3869323730469\n",
      "11 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 4.763406753540039 85.45130920410156\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 24.979461669921875\n",
      "11 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.477447986602783 101.96096801757812\n",
      "sparsity check 2.0\n",
      "err_spxsp 151.75888061523438\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.007801956777257146\n",
      "0 0.0077045265225024195\n",
      "1 0.007557220336821047\n",
      "2 0.007428027343848953\n",
      "3 0.0073578828832978616\n",
      "4 0.0073267016723548295\n",
      "5 0.00726261900854297\n",
      "6 0.007232474406919209\n",
      "7 0.007224085984489648\n",
      "err after  0.007223143174996949\n",
      "11 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.661385178565979 43.439674377441406\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 255.1707000732422\n",
      "11 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.102044105529785 74.12847900390625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 668.2911987304688\n",
      "11 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.3249306678771973 48.320899963378906\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 931.6473388671875\n",
      "11 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.485865592956543 92.4287109375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 606.8515625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.009521575186226983\n",
      "0 0.008885096352969413\n",
      "1 0.00844621128453582\n",
      "2 0.008224733073802781\n",
      "3 0.00808635400608182\n",
      "4 0.007994616684300127\n",
      "5 0.007912736107755336\n",
      "6 0.007857048460209626\n",
      "7 0.007838971341698198\n",
      "err after  0.007837122280761832\n",
      "12 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.7359407544136047 28.96307373046875\n",
      "sparsity check 2.0\n",
      "err_spxsp 459.03265380859375\n",
      "12 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 7.142163276672363 107.61636352539062\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 34.859439849853516\n",
      "12 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.742855072021484 96.17832946777344\n",
      "sparsity check 2.0\n",
      "err_spxsp 165.56768798828125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.008733419685086119\n",
      "0 0.008604481594375102\n",
      "1 0.008424637102507404\n",
      "2 0.008266183245723369\n",
      "3 0.008174540676918696\n",
      "4 0.008135185358696617\n",
      "5 0.008069588571743225\n",
      "6 0.008036430344873224\n",
      "7 0.008026551049624686\n",
      "err after  0.008025427159736864\n",
      "12 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.6573299169540405 44.75455856323242\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 257.92022705078125\n",
      "12 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.611217021942139 84.40036010742188\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 712.8697509765625\n",
      "12 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.485652446746826 54.16070556640625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 937.5963134765625\n",
      "12 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.717796325683594 103.06694030761719\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 657.9125366210938\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.010307569817086915\n",
      "0 0.009839849943091394\n",
      "1 0.009357595390611095\n",
      "2 0.009063370333024068\n",
      "3 0.008921470787754515\n",
      "4 0.008801306135865161\n",
      "5 0.008711669966942281\n",
      "6 0.008658435401230236\n",
      "7 0.00863214187847916\n",
      "err after  0.008629674041003454\n",
      "13 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.8678313493728638 45.446475982666016\n",
      "sparsity check 2.0\n",
      "err_spxsp 448.99334716796875\n",
      "13 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 6.652777671813965 98.14219665527344\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 30.110942840576172\n",
      "13 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.245702743530273 132.1676025390625\n",
      "sparsity check 2.0\n",
      "err_spxsp 158.69175720214844\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.00962828208321298\n",
      "0 0.009483180725510465\n",
      "1 0.00927194653195329\n",
      "2 0.009091275498576579\n",
      "3 0.008979759360954631\n",
      "4 0.008918634934161673\n",
      "5 0.008863969842423103\n",
      "6 0.008830417091303389\n",
      "7 0.008818826272545266\n",
      "err after  0.008817444202577462\n",
      "13 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.5746593475341797 50.77370834350586\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 247.99655151367188\n",
      "13 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.322146415710449 92.70001983642578\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 708.2669677734375\n",
      "13 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.790274143218994 59.2503662109375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 930.292724609375\n",
      "13 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 10.354469299316406 119.71601867675781\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 653.159423828125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.011778301755839493\n",
      "0 0.011183405913470779\n",
      "1 0.01066045254628989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.010320439498173073\n",
      "3 0.010125519478606293\n",
      "4 0.009988101865019416\n",
      "5 0.00990422166614735\n",
      "6 0.009838311867497396\n",
      "7 0.009818172229643096\n",
      "err after  0.009815789566346211\n",
      "14 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.8852958679199219 49.01214599609375\n",
      "sparsity check 2.0\n",
      "err_spxsp 458.6206359863281\n",
      "14 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 6.214960098266602 83.73635864257812\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 27.95117950439453\n",
      "14 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.14232349395752 123.88059997558594\n",
      "sparsity check 2.0\n",
      "err_spxsp 156.77651977539062\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.010913521651673364\n",
      "0 0.010760401000879938\n",
      "1 0.010542182128119748\n",
      "2 0.010347242216084851\n",
      "3 0.010228489580185851\n",
      "4 0.010157999220609781\n",
      "5 0.010095279929373646\n",
      "6 0.010057055565994233\n",
      "7 0.01004447753803106\n",
      "err after  0.010042942161817336\n",
      "14 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.6825950145721436 59.49000549316406\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 280.6371154785156\n",
      "14 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.72915267944336 108.80221557617188\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 721.3472290039062\n",
      "14 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.4604997634887695 66.6436538696289\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 992.2786865234375\n",
      "14 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 12.539511680603027 140.6885528564453\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 663.0\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.013524762664019363\n",
      "0 0.012939315201947466\n",
      "1 0.012332250174949877\n",
      "2 0.011913743826880818\n",
      "3 0.011687530899507692\n",
      "4 0.011532334468938643\n",
      "5 0.011418528207286727\n",
      "6 0.01133859678520821\n",
      "7 0.011314167491946137\n",
      "err after  0.011311198846669868\n",
      "15 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.7499971389770508 32.24931335449219\n",
      "sparsity check 2.0\n",
      "err_spxsp 545.1382446289062\n",
      "15 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 14.510701179504395 235.37225341796875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 41.72749710083008\n",
      "15 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.068183898925781 115.11376953125\n",
      "sparsity check 2.0\n",
      "err_spxsp 182.6368865966797\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.01271065329638077\n",
      "0 0.012523907236754894\n",
      "1 0.012228196868818486\n",
      "2 0.011979136528680101\n",
      "3 0.01182219572365284\n",
      "4 0.011724314175808104\n",
      "5 0.011660235650197137\n",
      "6 0.01161965139908716\n",
      "7 0.011604229814111022\n",
      "err after  0.011602286343986634\n",
      "15 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.8026307225227356 55.31009292602539\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 268.48284912109375\n",
      "15 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 10.456094741821289 127.07269287109375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 698.3086547851562\n",
      "15 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 5.250005722045898 76.64804077148438\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1034.540771484375\n",
      "15 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 16.943462371826172 184.19097900390625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 658.7623291015625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.016131263571878662\n",
      "0 0.015609147365466924\n",
      "1 0.014926914027455496\n",
      "2 0.014392990287888097\n",
      "3 0.014069209075387334\n",
      "4 0.013845292633050121\n",
      "5 0.013711896004679147\n",
      "6 0.01361882946730475\n",
      "7 0.013590586324426113\n",
      "err after  0.013587155230197823\n",
      "16 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.7031572461128235 39.553504943847656\n",
      "sparsity check 2.0\n",
      "err_spxsp 576.643310546875\n",
      "16 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 14.734848022460938 226.288330078125\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 32.68670654296875\n",
      "16 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.064970016479492 107.99835205078125\n",
      "sparsity check 2.0\n",
      "err_spxsp 170.79592895507812\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.014902133611030877\n",
      "0 0.014753607221791754\n",
      "1 0.014482990161923226\n",
      "2 0.014213328733603703\n",
      "3 0.014027686818735674\n",
      "4 0.013905327567044878\n",
      "5 0.013826913997036172\n",
      "6 0.013782929079752648\n",
      "7 0.013765237799816532\n",
      "err after  0.013762972706899745\n",
      "16 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.7081196308135986 61.33159637451172\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 296.84735107421875\n",
      "16 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.19138240814209 131.4586944580078\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 672.5185546875\n",
      "16 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.406538009643555 87.10612487792969\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1081.16357421875\n",
      "16 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 18.050817489624023 199.32147216796875\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 643.5625610351562\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.01914354339169222\n",
      "0 0.01854308389738435\n",
      "1 0.01780228505958803\n",
      "2 0.017131124950537924\n",
      "3 0.016730727249523625\n",
      "4 0.016526913936104393\n",
      "5 0.016374777900637127\n",
      "6 0.01625069793590228\n",
      "7 0.016214801729802275\n",
      "err after  0.016210695801419206\n",
      "17 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.6175225973129272 31.09278106689453\n",
      "sparsity check 2.0\n",
      "err_spxsp 578.5953369140625\n",
      "17 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 20.491432189941406 312.4012451171875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 45.78636932373047\n",
      "17 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.419378280639648 87.8407211303711\n",
      "sparsity check 2.0\n",
      "err_spxsp 198.60801696777344\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.01748249217416742\n",
      "0 0.017320879986073123\n",
      "1 0.01705753498026752\n",
      "2 0.01678471929335501\n",
      "3 0.016585993420449086\n",
      "4 0.016452219380880706\n",
      "5 0.016363548347726464\n",
      "6 0.01631281240042881\n",
      "7 0.01629207908263197\n",
      "err after  0.01628936164343031\n",
      "17 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.6299054622650146 46.137115478515625\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 278.4276428222656\n",
      "17 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 12.34758186340332 142.77810668945312\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 665.1979370117188\n",
      "17 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.5485100746154785 97.68037414550781\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1103.933837890625\n",
      "17 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 21.851049423217773 235.60986328125\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 646.8123779296875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.021146894709090702\n",
      "0 0.020707744493847713\n",
      "1 0.02000455000961665\n",
      "2 0.01930619205086259\n",
      "3 0.01887928590440424\n",
      "4 0.01863967823010171\n",
      "5 0.01844661014911253\n",
      "6 0.01834139452330419\n",
      "7 0.018306969566765474\n",
      "err after  0.018303109540283913\n",
      "18 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.6347640752792358 28.83267593383789\n",
      "sparsity check 2.0\n",
      "err_spxsp 616.0927734375\n",
      "18 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 23.034149169921875 370.720947265625\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 31.762252807617188\n",
      "18 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.185574531555176 56.846923828125\n",
      "sparsity check 2.0\n",
      "err_spxsp 189.27565002441406\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.019142000277497573\n",
      "0 0.019048552254389506\n",
      "1 0.01886703635682352\n",
      "2 0.01863306220548111\n",
      "3 0.018439910334564047\n",
      "4 0.018304014123714296\n",
      "5 0.018210981579613872\n",
      "6 0.018158185921492986\n",
      "7 0.018136910566681763\n",
      "err after  0.018134221583750332\n",
      "18 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.5296947956085205 40.16176986694336\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 293.8059997558594\n",
      "18 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.977132797241211 134.37289428710938\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 650.6941528320312\n",
      "18 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err 259 8.413719177246094 102.36980438232422\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1109.455322265625\n",
      "18 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 19.559226989746094 214.3619384765625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 637.5001220703125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.022887061979417922\n",
      "0 0.022449306710768724\n",
      "1 0.021774466909846524\n",
      "2 0.021092464099638164\n",
      "3 0.020701367095171008\n",
      "4 0.020457699669350404\n",
      "5 0.02023662040664931\n",
      "6 0.020139342890615808\n",
      "7 0.020105552350287326\n",
      "err after  0.02010175507166423\n",
      "19 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.4955848455429077 21.59209442138672\n",
      "sparsity check 2.0\n",
      "err_spxsp 632.8014526367188\n",
      "19 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 26.82746124267578 440.80535888671875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 35.66859436035156\n",
      "19 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.3917524814605713 45.531070709228516\n",
      "sparsity check 2.0\n",
      "err_spxsp 197.9910125732422\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.0208260702129337\n",
      "0 0.020745682923006825\n",
      "1 0.02058293875597883\n",
      "2 0.02035677158346516\n",
      "3 0.020162198732577963\n",
      "4 0.020023514323838754\n",
      "5 0.019929526584746782\n",
      "6 0.019876176429534098\n",
      "7 0.019854560912790475\n",
      "err after  0.0198518901161151\n",
      "19 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.4759000539779663 31.780792236328125\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 303.4912109375\n",
      "19 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.738842010498047 130.3482666015625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 643.0333862304688\n",
      "19 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.842428207397461 104.52023315429688\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1123.9803466796875\n",
      "19 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 18.268531799316406 201.9061279296875\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 639.7022705078125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.02417581609915942\n",
      "0 0.023774454850354232\n",
      "1 0.023161306064139353\n",
      "2 0.022511579572892515\n",
      "3 0.02208342911762884\n",
      "4 0.02181737849241472\n",
      "5 0.021647642792231636\n",
      "6 0.021554447106609587\n",
      "7 0.02152102031686809\n",
      "err after  0.0215172207535943\n",
      "20 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.46269690990448 23.789030075073242\n",
      "sparsity check 2.0\n",
      "err_spxsp 627.80322265625\n",
      "20 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 25.8596134185791 376.87982177734375\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 38.902191162109375\n",
      "20 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.6829347610473633 44.72322082519531\n",
      "sparsity check 2.0\n",
      "err_spxsp 192.988525390625\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.022266392785240896\n",
      "0 0.022189861523656873\n",
      "1 0.022032427827070933\n",
      "2 0.021809735626447946\n",
      "3 0.021619116065267008\n",
      "4 0.02148302649948164\n",
      "5 0.021390758622146677\n",
      "6 0.021338358896173304\n",
      "7 0.021316865691915154\n",
      "err after  0.02131421020749258\n",
      "20 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.4093712568283081 31.632930755615234\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 295.97003173828125\n",
      "20 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.72195816040039 130.06201171875\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 646.0216674804688\n",
      "20 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.194913864135742 108.16544342041016\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1126.1962890625\n",
      "20 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 17.44991683959961 194.72579956054688\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 645.6093139648438\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.025643584587669466\n",
      "0 0.025250384700484574\n",
      "1 0.024653095635585487\n",
      "2 0.024029093998251483\n",
      "3 0.02363000885816291\n",
      "4 0.02339472994208336\n",
      "5 0.02320627088920446\n",
      "6 0.023106771819584537\n",
      "7 0.023070048417139333\n",
      "err after  0.023065878936904483\n",
      "21 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.49942612648010254 25.68370246887207\n",
      "sparsity check 2.0\n",
      "err_spxsp 617.1044921875\n",
      "21 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 25.381160736083984 371.72503662109375\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 44.16118621826172\n",
      "21 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.6498517990112305 64.83717346191406\n",
      "sparsity check 2.0\n",
      "err_spxsp 217.5623779296875\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.023987216816749424\n",
      "0 0.023876288996689254\n",
      "1 0.023681954917265102\n",
      "2 0.0234388597891666\n",
      "3 0.02324075822616578\n",
      "4 0.02309997802876751\n",
      "5 0.02300426938018063\n",
      "6 0.02295070726540871\n",
      "7 0.022928459624381503\n",
      "err after  0.022925591227249242\n",
      "21 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.44442063570022583 31.402313232421875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 323.2187194824219\n",
      "21 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.731934547424316 130.1085968017578\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 651.24755859375\n",
      "21 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.40298080444336 110.06365966796875\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1147.22314453125\n",
      "21 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 17.835256576538086 199.996337890625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 661.14990234375\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.026524251967202872\n",
      "0 0.02621719204034889\n",
      "1 0.025672267976915464\n",
      "2 0.025059281433641445\n",
      "3 0.024647816324431915\n",
      "4 0.024387331344769336\n",
      "5 0.02421451887130388\n",
      "6 0.024124173243762925\n",
      "7 0.02409066532709403\n",
      "err after  0.024086856792564504\n",
      "22 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.4224544167518616 23.640003204345703\n",
      "sparsity check 2.0\n",
      "err_spxsp 575.6595458984375\n",
      "22 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 22.80819320678711 328.1660461425781\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 46.73805236816406\n",
      "22 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.7165780067443848 43.95538330078125\n",
      "sparsity check 2.0\n",
      "err_spxsp 210.42845153808594\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.024767294024059083\n",
      "0 0.024703341019630898\n",
      "1 0.02455983422260033\n",
      "2 0.02434533064297284\n",
      "3 0.024156558996764943\n",
      "4 0.024019369418965653\n",
      "5 0.023925242501718458\n",
      "6 0.02387214124610182\n",
      "7 0.023850149962527212\n",
      "err after  0.023847406628192402\n",
      "22 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.3471965789794922 29.503713607788086\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 282.35943603515625\n",
      "22 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 10.806501388549805 118.994140625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 648.0902099609375\n",
      "22 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.99416732788086 105.44868469238281\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1138.8355712890625\n",
      "22 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 15.816751480102539 176.43234252929688\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 659.9325561523438\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.02629488322418183\n",
      "0 0.026004705909144832\n",
      "1 0.025530400889692828\n",
      "2 0.024984606439829804\n",
      "3 0.024611133325379342\n",
      "4 0.024368741189391585\n",
      "5 0.024212247615650995\n",
      "6 0.024126677180902334\n",
      "7 0.02409594485652633\n",
      "err after  0.0240925397411047\n",
      "23 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.43118247389793396 19.59784507751465\n",
      "sparsity check 2.0\n",
      "err_spxsp 571.76953125\n",
      "23 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 29.677505493164062 390.343994140625\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 49.570430755615234\n",
      "23 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.0918548107147217 33.60043716430664\n",
      "sparsity check 2.0\n",
      "err_spxsp 217.71434020996094\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err before 0.024686297179869143\n",
      "0 0.024619138741400093\n",
      "1 0.02448570535852923\n",
      "2 0.024288107098982437\n",
      "3 0.024111829759931425\n",
      "4 0.023983364833839005\n",
      "5 0.023895839978649747\n",
      "6 0.023845393043302465\n",
      "7 0.02382456425766577\n",
      "err after  0.02382217447302537\n",
      "23 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.4147140383720398 30.37834930419922\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 285.81689453125\n",
      "23 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 10.03101634979248 111.66719818115234\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 652.3101806640625\n",
      "23 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.709882736206055 101.47591400146484\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1143.7740478515625\n",
      "23 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 13.360973358154297 151.68075561523438\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 660.3983154296875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.025351101474370807\n",
      "0 0.02512500385637395\n",
      "1 0.024723016747884685\n",
      "2 0.024248360812634928\n",
      "3 0.02392012151176459\n",
      "4 0.023710140394541668\n",
      "5 0.02356235024490161\n",
      "6 0.02348041617369745\n",
      "7 0.023451775294233812\n",
      "err after  0.023448644522432005\n",
      "24 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.35994768142700195 20.691722869873047\n",
      "sparsity check 2.0\n",
      "err_spxsp 561.4901123046875\n",
      "24 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 30.124713897705078 452.56591796875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 56.837188720703125\n",
      "24 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.9951047897338867 34.07427215576172\n",
      "sparsity check 2.0\n",
      "err_spxsp 243.93243408203125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.02397473958262708\n",
      "0 0.023919274448417127\n",
      "1 0.023806110584700946\n",
      "2 0.023628651331819128\n",
      "3 0.02346782501990674\n",
      "4 0.023352044907369418\n",
      "5 0.02327326385420747\n",
      "6 0.023223131771374028\n",
      "7 0.023203321929031517\n",
      "err after  0.023201206313387956\n",
      "24 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.3430088758468628 31.41326904296875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 242.37539672851562\n",
      "24 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.381708145141602 104.0279769897461\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 659.061767578125\n",
      "24 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.412044525146484 97.6587142944336\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1160.706298828125\n",
      "24 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.168164253234863 130.31600952148438\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 662.371826171875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.02403320951270871\n",
      "0 0.023831873211747734\n",
      "1 0.023499771537899505\n",
      "2 0.02310902723183972\n",
      "3 0.02282580505561782\n",
      "4 0.02263675013819011\n",
      "5 0.02251169388546259\n",
      "6 0.022439649867010303\n",
      "7 0.022412351660022978\n",
      "err after  0.022409390345274005\n",
      "25 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.3869159519672394 22.770124435424805\n",
      "sparsity check 2.0\n",
      "err_spxsp 555.0198364257812\n",
      "25 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 27.322450637817383 400.63885498046875\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 58.238224029541016\n",
      "25 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.5710158348083496 30.08340072631836\n",
      "sparsity check 2.0\n",
      "err_spxsp 250.482177734375\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.02289510186528787\n",
      "0 0.02283034678112017\n",
      "1 0.02272180557338288\n",
      "2 0.02256352461699862\n",
      "3 0.02242115724584437\n",
      "4 0.02233002395951189\n",
      "5 0.02226345993767609\n",
      "6 0.02220567582116928\n",
      "7 0.022188793791428907\n",
      "err after  0.02218690402514767\n",
      "25 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.38661834597587585 35.7431640625\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 252.5472412109375\n",
      "25 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.843864440917969 97.49653625488281\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 673.5311889648438\n",
      "25 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.065427780151367 92.47554016113281\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1185.656494140625\n",
      "25 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.334169387817383 110.58619689941406\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 668.48486328125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.02271335124532925\n",
      "0 0.022488026661449112\n",
      "1 0.022176667727762833\n",
      "2 0.02181988041047589\n",
      "3 0.021564313381531974\n",
      "4 0.021398366279754555\n",
      "5 0.02128350424391101\n",
      "6 0.02122148868147633\n",
      "7 0.02119805692200316\n",
      "err after  0.02119518702966161\n",
      "26 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.33939361572265625 24.687515258789062\n",
      "sparsity check 2.0\n",
      "err_spxsp 584.8014526367188\n",
      "26 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 19.806175231933594 253.63616943359375\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 73.47505950927734\n",
      "26 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.794318199157715 34.187652587890625\n",
      "sparsity check 2.0\n",
      "err_spxsp 258.0458679199219\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.02177590789506212\n",
      "0 0.021696055242500734\n",
      "1 0.02157600299688056\n",
      "2 0.021419640204840107\n",
      "3 0.021284674017806537\n",
      "4 0.021188398721278645\n",
      "5 0.02112552752805641\n",
      "6 0.02108274868078297\n",
      "7 0.02106571269177948\n",
      "err after  0.02106381250268896\n",
      "26 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.29136475920677185 33.925437927246094\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 267.92828369140625\n",
      "26 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.205705642700195 90.74765014648438\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 689.6766357421875\n",
      "26 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.480253219604492 85.7877197265625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1202.979736328125\n",
      "26 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.24962329864502 99.54862976074219\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 680.776611328125\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.021054717857623473\n",
      "0 0.020818497410800774\n",
      "1 0.020523392558970954\n",
      "2 0.02020360724418424\n",
      "3 0.01998968655243516\n",
      "4 0.019835643244732637\n",
      "5 0.019728281313291518\n",
      "6 0.01966837868167204\n",
      "7 0.019647007942694472\n",
      "err after  0.019644145228085108\n",
      "27 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.35474395751953125 19.73514175415039\n",
      "sparsity check 2.0\n",
      "err_spxsp 530.1502685546875\n",
      "27 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 16.956192016601562 237.40240478515625\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 73.03479766845703\n",
      "27 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.6056606769561768 35.501708984375\n",
      "sparsity check 2.0\n",
      "err_spxsp 278.6376953125\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.020106058196688537\n",
      "0 0.02003809726011241\n",
      "1 0.01994418011236121\n",
      "2 0.01981199416331947\n",
      "3 0.019693947506311815\n",
      "4 0.019605721809057286\n",
      "5 0.019544808041246142\n",
      "6 0.01950889367799391\n",
      "7 0.019493330248224083\n",
      "err after  0.019491309096338227\n",
      "27 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.3200950622558594 31.062185287475586\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 255.93637084960938\n",
      "27 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.254373073577881 85.79109954833984\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1220.75146484375\n",
      "27 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.674424171447754 100.35948944091797\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 705.2437744140625\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.01965797566299443\n",
      "0 0.019392296351725236\n",
      "1 0.01911052834111615\n",
      "2 0.018817507596395444\n",
      "3 0.0186170900669822\n",
      "4 0.01847890793942497\n",
      "5 0.018376874348177807\n",
      "6 0.018323792650335236\n",
      "7 0.0183054153167177\n",
      "err after  0.01830240330491506\n",
      "28 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err 259 0.44504135847091675 19.529226303100586\n",
      "sparsity check 2.0\n",
      "err_spxsp 552.3676147460938\n",
      "28 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 14.140832901000977 164.17196655273438\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 84.20087432861328\n",
      "28 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.653510332107544 34.717567443847656\n",
      "sparsity check 2.0\n",
      "err_spxsp 279.8195495605469\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.018810092569765402\n",
      "0 0.01872227059720899\n",
      "1 0.018621895811520517\n",
      "2 0.018492562368919607\n",
      "3 0.018380669574980857\n",
      "4 0.018297470993275056\n",
      "5 0.0182381572376471\n",
      "6 0.018205189990112558\n",
      "7 0.018191416636909707\n",
      "err after  0.018189188211181317\n",
      "28 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.4417344331741333 28.344186782836914\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 220.57278442382812\n",
      "28 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.753557205200195 90.21589660644531\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 749.7236328125\n",
      "28 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.9598212242126465 85.65380859375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1203.3084716796875\n",
      "28 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.883756160736084 101.3740234375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 745.5717163085938\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.01978276750378427\n",
      "0 0.01943834263511235\n",
      "1 0.0191204874390678\n",
      "2 0.0188218086877896\n",
      "3 0.018620597456902033\n",
      "4 0.018487986093532527\n",
      "5 0.018391366676951293\n",
      "6 0.018334006163058802\n",
      "7 0.01831496969680302\n",
      "err after  0.018311661980987992\n",
      "29 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.459877610206604 17.799528121948242\n",
      "sparsity check 2.0\n",
      "err_spxsp 557.77587890625\n",
      "29 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 17.49834442138672 204.24310302734375\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 96.79025268554688\n",
      "29 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 2.163116455078125 35.96844482421875\n",
      "sparsity check 2.0\n",
      "err_spxsp 337.1898498535156\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.01889083181595197\n",
      "0 0.01871921141355415\n",
      "1 0.018589381135825533\n",
      "2 0.0184631154879753\n",
      "3 0.018354944522798178\n",
      "4 0.018273111836606404\n",
      "5 0.01821353620107402\n",
      "6 0.01818073533468123\n",
      "7 0.018166972344261012\n",
      "err after  0.018164478493417846\n",
      "29 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.4718419313430786 28.855911254882812\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 308.02044677734375\n",
      "29 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.839783668518066 143.23260498046875\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 825.468505859375\n",
      "29 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 6.509264945983887 86.42523193359375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1185.4405517578125\n",
      "29 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 8.599905967712402 118.29830169677734\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 813.0379638671875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.023200382813229226\n",
      "0 0.022511646915518213\n",
      "1 0.022031370768672787\n",
      "2 0.021638215708662756\n",
      "3 0.021392395214206772\n",
      "4 0.021236253440292785\n",
      "5 0.021119514807651285\n",
      "6 0.021041416683146963\n",
      "7 0.02101632356789196\n",
      "err after  0.021011632888985332\n",
      "30 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.30279022455215454 21.759960174560547\n",
      "sparsity check 2.0\n",
      "err_spxsp 416.4352722167969\n",
      "30 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 10.563793182373047 151.03836059570312\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 128.4293975830078\n",
      "30 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 3.4879391193389893 46.91109848022461\n",
      "sparsity check 2.0\n",
      "err_spxsp 312.7381591796875\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.022171456890646368\n",
      "0 0.02182301177890622\n",
      "1 0.021602524277113844\n",
      "2 0.021418315525806975\n",
      "3 0.02127362379906117\n",
      "4 0.021168349016079446\n",
      "5 0.021092623905133223\n",
      "6 0.02104857259473647\n",
      "7 0.021029882358561736\n",
      "err after  0.021026070116931805\n",
      "30 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.27457132935523987 32.10887145996094\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 165.90939331054688\n",
      "30 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 9.376359939575195 231.818603515625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 900.7142944335938\n",
      "30 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 7.333930015563965 108.60453796386719\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1259.464111328125\n",
      "30 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.966740608215332 197.999755859375\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 880.8779296875\n",
      "dict_keys(['self_attn.q_proj.weight', 'self_attn.k_proj.weight', 'self_attn.v_proj.weight', 'self_attn.o_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.06677899759961292\n",
      "0 0.06332205508078914\n",
      "1 0.060433571285102516\n",
      "2 0.05916836214601062\n",
      "3 0.05870526714716107\n",
      "4 0.05816223841975443\n",
      "5 0.05766948279051576\n",
      "6 0.05720336908416357\n",
      "7 0.05704031133063836\n",
      "err after  0.057010116724995896\n",
      "31 self_attn.q_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 0.4644637703895569 13.98731803894043\n",
      "sparsity check 2.0\n",
      "err_spxsp 561.703857421875\n",
      "31 self_attn.v_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 7.750393867492676 113.21943664550781\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 106.05416870117188\n",
      "31 self_attn.o_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 4.661677360534668 121.43478393554688\n",
      "sparsity check 2.0\n",
      "err_spxsp 374.235107421875\n",
      "dict_keys(['self_attn.k_proj.weight', 'mlp.gate_proj.weight', 'mlp.up_proj.weight', 'mlp.down_proj.weight'])\n",
      "err before 0.06016430800082162\n",
      "0 0.058963795949239284\n",
      "1 0.058340631556347944\n",
      "2 0.057843480237352196\n",
      "3 0.05748621480597649\n",
      "4 0.05719905836303951\n",
      "5 0.056914163345936686\n",
      "6 0.05670244296925375\n",
      "7 0.05661640380276367\n",
      "err after  0.05659882245527115\n",
      "31 self_attn.k_proj\n",
      "Pruning ...\n",
      "mid 1024\n",
      "err 259 0.5610796809196472 23.202096939086914\n",
      "sparsity check 1.99951171875\n",
      "err_spxsp 235.21299743652344\n",
      "31 mlp.up_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 15.976821899414062 530.379150390625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1294.260986328125\n",
      "31 mlp.gate_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 11.394399642944336 219.8646697998047\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1676.55419921875\n",
      "31 mlp.down_proj\n",
      "Pruning ...\n",
      "mid 4096\n",
      "err 259 40.738834381103516 2478.81494140625\n",
      "sparsity check 1.9998256138392858\n",
      "err_spxsp 1113.238037109375\n",
      "total time 28509.65911269188\n"
     ]
    }
   ],
   "source": [
    "import cupy\n",
    "\n",
    "def my_pack(x):\n",
    "    x = (x == 1).to(torch.uint8)\n",
    "    out = torch.zeros((x.shape[0]//8), device=x.device, dtype=torch.uint8)\n",
    "    for i in range(8):\n",
    "        out += x[i::8] << (7 - i)\n",
    "    return out\n",
    "\n",
    "@torch.compile\n",
    "def my_unpack(x):\n",
    "    out = torch.zeros((x.shape[0], 8), device=x.device, dtype=torch.int8)\n",
    "    for i in range(8):\n",
    "        out[:,i] = (x >> (7 - i)) & 1\n",
    "    return out.flatten() * 2 - 1\n",
    "\n",
    "def power_iteration(A, num_iters=5):\n",
    "    \"\"\"\n",
    "    Performs power iteration to compute the top singular vectors and value.\n",
    "    \n",
    "    Arguments:\n",
    "        A (torch.Tensor): The input matrix of shape (m, n).\n",
    "        num_iters (int): Number of iterations to perform.\n",
    "    \n",
    "    Returns:\n",
    "        u (torch.Tensor): Dominant left singular vector (m,).\n",
    "        sigma (torch.Tensor): Dominant singular value (scalar).\n",
    "        v (torch.Tensor): Dominant right singular vector (n,).\n",
    "    \"\"\"\n",
    "    # Start with a random vector on the appropriate device\n",
    "    n = A.shape[1]\n",
    "    v = torch.randn(n, device=A.device)\n",
    "    v = v / torch.norm(v)\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "        # Multiply A*v\n",
    "        u = torch.mv(A, v)\n",
    "        u_norm = torch.norm(u)\n",
    "        if u_norm == 0:\n",
    "            break\n",
    "        u = u / u_norm\n",
    "        \n",
    "        # Multiply A^T*u\n",
    "        v = torch.mv(A.t(), u)\n",
    "        v_norm = torch.norm(v)\n",
    "        if v_norm == 0:\n",
    "            break\n",
    "        v = v / v_norm\n",
    "    \n",
    "    # Estimate the dominant singular value as ||A*v||\n",
    "    sigma = torch.norm(torch.mv(A, v))\n",
    "    # The left singular vector corresponding to sigma:\n",
    "    u = torch.mv(A, v) / sigma\n",
    "    return u, sigma, v\n",
    "\n",
    "def svd_abs2(W):\n",
    "    Sg = W.sign()\n",
    "    Sg[Sg == 0] = 1\n",
    "    u, s, v = power_iteration(W.abs(), num_iters=5)\n",
    "    apx = s * torch.ger(u, v)\n",
    "    \n",
    "    return u * s, Sg, v\n",
    "\n",
    "class BitLinear(nn.Module):\n",
    "    def __init__(self, b):\n",
    "        super().__init__()\n",
    "        \n",
    "        #u, b, v = svd_abs(w.float())\n",
    "        b_packed = my_pack(b.flatten())\n",
    "        self.shape = b.shape\n",
    "        #print(b)\n",
    "        #print(my_unpack(b_packed).reshape(b.shape))\n",
    "        \n",
    "        self.register_buffer(\"bp\", b_packed)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.matmul(my_unpack(self.bp).reshape(self.shape).T.to(x.dtype))\n",
    "        \n",
    "\n",
    "        \n",
    "class Mul(nn.Module):\n",
    "    def __init__(self, w):\n",
    "        super().__init__()\n",
    "        #print(\"w\", w.amin().item(), w.median().item(), w.amax().item())\n",
    "        \n",
    "        self.register_buffer(\"w\", w)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * self.w.to(x.dtype)\n",
    "        \n",
    "\n",
    "def replace(lx):\n",
    "    dev = \"cuda\"\n",
    "    m1 = lx.weight.B\n",
    "    m2 = lx.weight.A\n",
    "    \n",
    "    u1, b1, v1 = svd_abs2(m1.float())\n",
    "    u2, b2, v2 = svd_abs2(m2.float())\n",
    "    \n",
    "    lx2 = nn.Sequential(\n",
    "        Mul(v1),\n",
    "        BitLinear(b1),\n",
    "        Mul(u1*lx.weight.mid*v2),\n",
    "        BitLinear(b2),\n",
    "        Mul(u2)\n",
    "    )\n",
    "    return lx2\n",
    "\n",
    "@torch.no_grad()\n",
    "def opt_sequential(model, dataloader, dev):\n",
    "    print('Starting ...')\n",
    "    \n",
    "    model.cpu()\n",
    "    model.gradient_checkpointing_disable()\n",
    "    model.eval()\n",
    "    use_cache = model.config.use_cache\n",
    "    model.config.use_cache = False\n",
    "    layers = model.model.layers\n",
    "    \n",
    "\n",
    "    model.model.embed_tokens = model.model.embed_tokens.to(dev) \n",
    "    model.model.rotary_emb = model.model.rotary_emb.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (n_samples, model.seqlen, model.config.hidden_size), dtype=dtype, device=\"cpu\"\n",
    "    )\n",
    "    cache = {'i': 0, 'attention_mask': None}\n",
    "\n",
    "    class Catcher(nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "        def forward(self, inp, **kwargs):\n",
    "            inps[cache['i']] = inp\n",
    "            cache['i'] += 1\n",
    "            cache['attention_mask'] = kwargs['attention_mask']\n",
    "            cache['position_embeddings'] = kwargs['position_embeddings']\n",
    "            raise ValueError\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    for batch in dataloader:\n",
    "        try:\n",
    "            model(batch.unsqueeze(0).to(dev))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    comp_inps = inps.clone()\n",
    "    attention_mask = cache['attention_mask']\n",
    "    position_embeddings = cache['position_embeddings']\n",
    "\n",
    "    print('Ready.')\n",
    "\n",
    "    layers = model.model.layers\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i].to(dev)\n",
    "\n",
    "        subset = find_layers(layer)\n",
    "        for j in range(n_samples):\n",
    "            inps[j] = layer(inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "\n",
    "        imp = layer.mlp.down_proj.o_norm\n",
    "        \n",
    "        for name in [\n",
    "            \"self_attn.q_proj\",\n",
    "            \"self_attn.v_proj\",\n",
    "            \"self_attn.o_proj\",\n",
    "            \"self_attn.k_proj\",\n",
    "            \"mlp.up_proj\",\n",
    "            \"mlp.gate_proj\",\n",
    "            \"mlp.down_proj\",\n",
    "        ]:\n",
    "            #if \"gate_proj\" not in name:\n",
    "            #    continue\n",
    "            to_opt = {n: p for n, p in layer.named_parameters() if \"weight\" in n and \"layernorm\" not in n}\n",
    "            if len(to_opt) > 0 and ((\"q_proj\" in name and i >= 1) or \"k_proj\" in name):\n",
    "                \n",
    "                for n, p in to_opt.items():\n",
    "                    p.requires_grad = True\n",
    "                print(to_opt.keys())\n",
    "\n",
    "                #opt = torch.optim.Adam(to_opt.values(), lr=1e-5)\n",
    "                #opt = Lamb(to_opt.values(), lr=1e-3, weight_decay=1e-4)\n",
    "                #sch = torch.optim.lr_scheduler.LinearLR(opt, start_factor=1e-8, total_iters=16)\n",
    "                lr = 3e-5\n",
    "                opt = BF16FusedAdamW(to_opt.values(), lr, weight_decay=1e-4)\n",
    "                sch = torch.optim.lr_scheduler.OneCycleLR(opt, lr, total_steps=n_samples*8 // 8, cycle_momentum=False)\n",
    "                err_before = 0\n",
    "                for j in range(n_samples):\n",
    "                    cur_out = layer(comp_inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "                    err_before += ((cur_out.float() - inps[j].cuda().float()).square() * imp).mean().item()\n",
    "\n",
    "                print(\"err before\", err_before)\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    for ep in range(8):\n",
    "                        err_total = 0\n",
    "                        for j in range(n_samples):\n",
    "                            cur_out = layer(comp_inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "                            err = ((cur_out.float() - inps[j].cuda().float()).square() * imp).sum()\n",
    "                            err.backward()\n",
    "                            if j % 8 == 7:\n",
    "                                opt.step()\n",
    "                                sch.step()\n",
    "                                layer.zero_grad(set_to_none=True)\n",
    "                            err_total += err.item() / inps.shape[1] / inps.shape[2]\n",
    "                        print(ep, err_total)\n",
    "\n",
    "                err_after = 0\n",
    "                for j in range(n_samples):\n",
    "                    cur_out = layer(comp_inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "                    err_after += ((cur_out.float() - inps[j].cuda().float()).square() * imp).mean().item()\n",
    "                print(\"err after \", err_after)\n",
    "                        \n",
    "            #gpts[name].free()\n",
    "            \n",
    "            print(i, name)\n",
    "            print('Pruning ...')\n",
    "            lx = subset[name]\n",
    "            \n",
    "            s1 = time.time()\n",
    "            #W2 = go_admm(lx)\n",
    "            W2, Ac, Bb, mid, = factorize(lx)\n",
    "            W2 = W2.T\n",
    "            err_spxsp = (W2.T - lx.weight).square().sum().item()\n",
    "            print(\"err_spxsp\", err_spxsp)\n",
    "            \n",
    "            \n",
    "            lx.weight.data = W2.T.to(lx.weight)\n",
    "            lx.weight.A = Ac\n",
    "            lx.weight.B = Bb\n",
    "            lx.weight.mid = mid\n",
    "            parts = name.split('.')\n",
    "            block = getattr(layer, parts[0])\n",
    "            setattr(block, parts[1], replace(lx))\n",
    "            \n",
    "            \n",
    "            \n",
    "        for j in range(n_samples):\n",
    "            comp_inps[j] = layer(comp_inps[j].unsqueeze(0).cuda(), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "            \n",
    "        layers[i] = layer.cpu()\n",
    "        del layer\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "start = time.time()\n",
    "model.cpu()\n",
    "opt_sequential(model, dataloader, DEV)\n",
    "print(\"total time\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef7480f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:53:30.401542Z",
     "iopub.status.busy": "2023-12-26T11:53:30.401087Z",
     "iopub.status.idle": "2023-12-26T11:53:30.420226Z",
     "shell.execute_reply": "2023-12-26T11:53:30.419662Z"
    },
    "papermill": {
     "duration": 0.038429,
     "end_time": "2023-12-26T11:53:30.422134",
     "exception": false,
     "start_time": "2023-12-26T11:53:30.383705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def opt_eval(model, testenc, dev, dataset: str, log_wandb: bool = False):\n",
    "    print('Evaluating ...')\n",
    "\n",
    "    testenc = testenc.input_ids\n",
    "    nsamples = testenc.numel() // model.seqlen\n",
    "\n",
    "    use_cache = model.config.use_cache\n",
    "    model.config.use_cache = False\n",
    "    layers = model.model.layers\n",
    "\n",
    "    model.model.embed_tokens = model.model.embed_tokens.to(dev)\n",
    "    model.model.rotary_emb = model.model.rotary_emb.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (nsamples, model.seqlen, model.config.hidden_size), dtype=dtype, device=dev\n",
    "    )\n",
    "    cache = {'i': 0, 'attention_mask': None}\n",
    "\n",
    "    class Catcher(nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "        def forward(self, inp, **kwargs):\n",
    "            inps[cache['i']] = inp\n",
    "            cache['i'] += 1\n",
    "            cache['attention_mask'] = kwargs['attention_mask']\n",
    "            cache['position_embeddings'] = kwargs['position_embeddings']\n",
    "            raise ValueError\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    for i in range(nsamples):\n",
    "        batch = testenc[:, (i * model.seqlen):((i + 1) * model.seqlen)].to(dev)\n",
    "        try:\n",
    "            model(batch)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    outs = torch.zeros_like(inps)\n",
    "    attention_mask = cache['attention_mask']\n",
    "    position_embeddings = cache['position_embeddings']\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        print(i)\n",
    "        layer = layers[i].to(dev)\n",
    "\n",
    "        \n",
    "        for j in range(nsamples):\n",
    "            outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, position_embeddings=position_embeddings)[0]\n",
    "        layers[i] = layer.cpu()\n",
    "        del layer\n",
    "        torch.cuda.empty_cache()\n",
    "        inps, outs = outs, inps\n",
    "\n",
    "    if model.model.norm is not None:\n",
    "        model.model.norm = model.model.norm.to(dev)\n",
    "    model.lm_head = model.lm_head.to(dev)\n",
    "\n",
    "    testenc = testenc.to(dev)\n",
    "    nlls = []\n",
    "    for i in range(nsamples):\n",
    "        hidden_states = inps[i].unsqueeze(0)\n",
    "        if model.model.norm is not None:\n",
    "            hidden_states = model.model.norm(hidden_states)\n",
    "        lm_logits = model.lm_head(hidden_states)\n",
    "        shift_logits = lm_logits[:, :-1, :].contiguous()\n",
    "        shift_labels = testenc[\n",
    "            :, (i * model.seqlen):((i + 1) * model.seqlen)\n",
    "        ][:, 1:]\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "        neg_log_likelihood = loss.float() * model.seqlen\n",
    "        nlls.append(neg_log_likelihood)\n",
    "    ppl = torch.exp(torch.stack(nlls).sum() / (nsamples * model.seqlen))\n",
    "    print(f\"Perplexity: {ppl.item():3f}\")\n",
    "    if log_wandb:\n",
    "         wandb.log({f'{dataset}/perplexity': ppl.item()})\n",
    "\n",
    "    model.config.use_cache = use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448fd6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T11:53:30.497357Z",
     "iopub.status.busy": "2023-12-26T11:53:30.496880Z",
     "iopub.status.idle": "2023-12-26T11:56:24.045683Z",
     "shell.execute_reply": "2023-12-26T11:56:24.044885Z"
    },
    "papermill": {
     "duration": 173.580751,
     "end_time": "2023-12-26T11:56:24.048044",
     "exception": false,
     "start_time": "2023-12-26T11:53:30.467293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok 128000 128001\n",
      "wikitext2\n",
      "Evaluating ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Perplexity: 8.918874\n"
     ]
    }
   ],
   "source": [
    "model.gradient_checkpointing_disable()\n",
    "model.eval()\n",
    "\n",
    "for dataset in ['wikitext2']:\n",
    "    dataloader, testloader = get_loaders(\n",
    "        dataset, seed=0, model=model_name, seqlen=model.seqlen\n",
    "    )\n",
    "    print(dataset)\n",
    "    opt_eval(model, testloader, DEV, dataset, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1397c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/mnt/nvme/llamapush/llama3-8B-dsf1bit-20-ft-rand.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e695e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1090.722145,
   "end_time": "2023-12-26T11:56:25.741463",
   "environment_variables": {},
   "exception": null,
   "input_path": "Llama prune-params-WU.ipynb",
   "output_path": "outputs/Llama-0.6-per_layer-admm-20-iterp15WU.ipynb",
   "parameters": {
    "iterative_prune": 15,
    "iters": 20,
    "sparsity": 0.6
   },
   "start_time": "2023-12-26T11:38:15.019318",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06d87db571ab4d88b82f52214601bb42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7ceac1ff43d4e279a2e938bbe2a9758",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b25d62f1cc0c4f73986ede9999476992",
       "tabbable": null,
       "tooltip": null,
       "value": 33
      }
     },
     "10900902714f449e933af1fbb5b4c688": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d15d5f8d6c74e0a8b2a6a56df56d8f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "62690d5acae24b38b50cb74283306762": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9c30a1d8ffe74cfdb177e547c15b771d",
       "placeholder": "",
       "style": "IPY_MODEL_b64151aeaf904f719d868882ef9e600f",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "84e75e03350d40dd8bf62fdd06a61df7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_62690d5acae24b38b50cb74283306762",
        "IPY_MODEL_06d87db571ab4d88b82f52214601bb42",
        "IPY_MODEL_e6f6ce88afbc4f6199222b97e1218d81"
       ],
       "layout": "IPY_MODEL_c4d01b52ee784af28749c6928e95c0dd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9c30a1d8ffe74cfdb177e547c15b771d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b25d62f1cc0c4f73986ede9999476992": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b64151aeaf904f719d868882ef9e600f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b7ceac1ff43d4e279a2e938bbe2a9758": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4d01b52ee784af28749c6928e95c0dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6f6ce88afbc4f6199222b97e1218d81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10900902714f449e933af1fbb5b4c688",
       "placeholder": "",
       "style": "IPY_MODEL_4d15d5f8d6c74e0a8b2a6a56df56d8f2",
       "tabbable": null,
       "tooltip": null,
       "value": " 33/33 [00:18&lt;00:00,  1.72it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
